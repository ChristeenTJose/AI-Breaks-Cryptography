{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Vs Cryptography.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ifoj9Ni9bqCh",
        "XDqOC1YPsPc9",
        "LoDll0HmzEcG",
        "lNYzSGIHOPe5"
      ],
      "toc_visible": true,
      "mount_file_id": "1slSwkBuWGoRWylq3dWehwdV-s7ZffKW1",
      "authorship_tag": "ABX9TyNQHu0nFdrytvCUpolD5T9H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristeenTJose/AI-vs.-Cryptography/blob/master/AI_vs_Cryptography.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slptdE5rZGMI"
      },
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULphdRRzZDit"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F7ShoG0dRGl"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVQMYsNg6IDQ"
      },
      "source": [
        "# cryptography"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o_6LZ4R6JWv",
        "outputId": "f382e15f-acdf-45c9-9c23-e9a700183588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def CaesarCipher_characterset():\n",
        "\treturn 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "def CaesarCipher_get_dict():\n",
        "\tx=CaesarCipher_characterset()\n",
        "\ty=range(len(x))\n",
        "\treturn dict(zip(x,y)),dict(zip(y,x))\n",
        "\n",
        "def CaesarCipher_encryption(plaintext,key):\n",
        "\tC2I,I2C=CaesarCipher_get_dict()\n",
        "\t#INPUTS\n",
        "\tplaintext=plaintext.upper()\n",
        "\tkey=int(key)\n",
        "\t#CEASAR CIPHER\n",
        "\tciphertext=[]\n",
        "\tfor word in plaintext.split(' '):\n",
        "\t\tciphertext.append(''.join([I2C[(C2I[i]+key)%26] for i in word]))\n",
        "\tciphertext=' '.join(ciphertext)\n",
        "\t#OUTPUTS\n",
        "\t#print('\\n\\n\\t\\tPlaintext:  ',plaintext)\n",
        "\t#print('\\n\\n\\t\\tCiphertext: ',ciphertext)\n",
        "\treturn ciphertext\n",
        "\n",
        "def CaesarCipher_decryption(ciphertext,key):\n",
        "\tC2I,I2C=CaesarCipher_get_dict()\n",
        "\t#INPUTS\n",
        "\tciphertext=ciphertext.upper()\n",
        "\tkey=int(key)\n",
        "\t#CEASAR CIPHER\n",
        "\tplaintext=[]\n",
        "\tfor word in ciphertext.split(' '):\n",
        "\t\tplaintext.append(''.join([I2C[(C2I[i]-key)%26] for i in word]))\n",
        "\tplaintext=' '.join(plaintext)\n",
        "\t#OUTPUTS\n",
        "\t#print('\\n\\n\\t\\tCiphertext: ',ciphertext)\n",
        "\t#print('\\n\\n\\t\\tPlaintext:  ',plaintext)\n",
        "\treturn plaintext\n",
        "\n",
        "def ROT13(plaintext):\n",
        "\tC2I,I2C=CaesarCipher_get_dict()\n",
        "\t#INPUTS\n",
        "\tplaintext=plaintext.upper()\n",
        "\tkey=13\n",
        "\t#CEASAR CIPHER\n",
        "\tciphertext=[]\n",
        "\tfor word in plaintext.split(' '):\n",
        "\t\tciphertext.append(''.join([I2C[(C2I[i]+key)%26] for i in word]))\n",
        "\tciphertext=' '.join(ciphertext)\n",
        "\t#OUTPUTS\n",
        "\t#print('\\n\\n\\t\\tPlaintext:  ',plaintext)\n",
        "\t#print('\\n\\n\\t\\tCiphertext: ',ciphertext)\n",
        "\treturn ciphertext\n",
        "\n",
        "def SimpleSubstitutionCipher_get_dict(keyword):\n",
        "\tx=CaesarCipher_characterset()\n",
        "\ty=''\n",
        "\tfor i in keyword:\n",
        "\t\tif i not in y:\n",
        "\t\t\ty+=i\n",
        "\tfor i in x:\n",
        "\t\tif i not in y:\n",
        "\t\t\ty+=i\n",
        "\treturn dict(zip(x,y)),dict(zip(y,x))\t\n",
        "\t\n",
        "def SimpleSubstitutionCipher_encryption(plaintext,keyword):\n",
        "\tplaintext=plaintext.upper()\n",
        "\tkeyword=keyword.upper()\t\n",
        "\tDict_Encrypt,_= SimpleSubstitutionCipher_get_dict(keyword)\n",
        "\tciphertext=''\n",
        "\tfor i in plaintext:\n",
        "\t\tif i == ' ':\n",
        "\t\t\tciphertext+=' '\n",
        "\t\telse:\n",
        "\t\t\tciphertext+=Dict_Encrypt[i]\n",
        "\treturn ciphertext\n",
        "\n",
        "def SimpleSubstitutionCipher_decryption(ciphertext,keyword):\n",
        "\tkeyword=keyword.upper()\t\n",
        "\t_,Dict_Decrypt= SimpleSubstitutionCipher_get_dict(keyword)\n",
        "\tplaintext=''\n",
        "\tfor i in ciphertext:\n",
        "\t\tif i == ' ':\n",
        "\t\t\tplaintext+=' '\n",
        "\t\telse:\n",
        "\t\t\tplaintext+=Dict_Decrypt[i]\n",
        "\treturn plaintext\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "\tkey=25\n",
        "\tprint(CaesarCipher_decryption(CaesarCipher_encryption(\"Christeen T Jose\",key),key))\n",
        "\tprint(ROT13(ROT13(\"Christeen T Jose\")))\n",
        "\tprint(SimpleSubstitutionCipher_decryption(SimpleSubstitutionCipher_encryption(\"flee at once we are discovered\",\"zebras\"),\"zebras\"))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CHRISTEEN T JOSE\n",
            "CHRISTEEN T JOSE\n",
            "FLEE AT ONCE WE ARE DISCOVERED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifoj9Ni9bqCh"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhMfJzEvcBgo"
      },
      "source": [
        "Name='Model 3.1 - SS 13 - 2020-10-03 16:15:34.173018.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woYkuv_ccejW"
      },
      "source": [
        "Note: First Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwroxLpIbvcv"
      },
      "source": [
        "Location='/content/drive/My Drive/AI Breaks Cryptography/Models/'\n",
        "model_SS.load_weights(Location+Name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDqOC1YPsPc9"
      },
      "source": [
        "# Caesar Cipher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLWXppeBGqn3"
      },
      "source": [
        "## Known-Plaintext Attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkVz4O0XHchW"
      },
      "source": [
        "### Fixed Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j_Of2MB3IUI"
      },
      "source": [
        "KEY=23"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qbHOIYVIcVQ"
      },
      "source": [
        "### Password Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1LM9ErHIll9"
      },
      "source": [
        "PASSWORD_SIZE=8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbtxwBwQIhGJ"
      },
      "source": [
        "### Dataset Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJUlD688IvUD"
      },
      "source": [
        "DATASET_SIZE=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvwi7iKxHydK"
      },
      "source": [
        "### Generation of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgoZawwY1KwZ",
        "outputId": "7ced4a53-13ce-48eb-d203-f71bd4ecce21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "CHOICES=CaesarCipher_characterset()\n",
        "CHOICES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PSNMcgN2R7p",
        "outputId": "f65430a8-bb3b-4063-9880-b90c3d873f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for i in range(DATASET_SIZE):\n",
        "  temp=''\n",
        "  for j in range(PASSWORD_SIZE):\n",
        "    temp+=random.choice(CHOICES)\n",
        "  x.append(temp)\n",
        "  y.append(CaesarCipher_encryption(temp,KEY))\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['BUEXRYKR', 'BRPBGHIQ', 'QRBZJJHK', 'BMBJPOYV', 'WEOCDQWP', 'BMTDGQUZ', 'FHZGPFJX', 'GLINQEDO', 'LNKXSRYA', 'EWMUSNCP', 'YLGRVFFL', 'MNPIDNRM', 'BEUVZYQH', 'ADDEOZIO', 'JQBEEFSS', 'YXIERKGB', 'WWBPKOWV', 'YVPFKWXM', 'DEGYMSLK', 'QQOESIOE', 'GNPTQOGP', 'JNYQSBLI', 'JTRRTTDO', 'RZXGUSZG', 'QLOMBVRZ', 'WLFRCGCN', 'NCDUZOPQ', 'WPQSIPTZ', 'ZYMNNNWR', 'JORCSGMV', 'BNNIANTG', 'MADJWWCI', 'LUAMWYVI', 'GRLSGXJG', 'GPFZNBYB', 'UTRKFBOW', 'RXZZYWUY', 'XSZDRPEU', 'IBKDONRS', 'ADEZPDUP', 'FMZAXLJR', 'FGQMVLPD', 'YZOHOWJD', 'JQQDPHVT', 'EFIVKZBN', 'PCNKNJFS', 'AZEKJUSC', 'SZIYPEFD', 'GFNIEXIQ', 'ZCDJRIBT']\n",
            "['YRBUOVHO', 'YOMYDEFN', 'NOYWGGEH', 'YJYGMLVS', 'TBLZANTM', 'YJQADNRW', 'CEWDMCGU', 'DIFKNBAL', 'IKHUPOVX', 'BTJRPKZM', 'VIDOSCCI', 'JKMFAKOJ', 'YBRSWVNE', 'XAABLWFL', 'GNYBBCPP', 'VUFBOHDY', 'TTYMHLTS', 'VSMCHTUJ', 'ABDVJPIH', 'NNLBPFLB', 'DKMQNLDM', 'GKVNPYIF', 'GQOOQQAL', 'OWUDRPWD', 'NILJYSOW', 'TICOZDZK', 'KZARWLMN', 'TMNPFMQW', 'WVJKKKTO', 'GLOZPDJS', 'YKKFXKQD', 'JXAGTTZF', 'IRXJTVSF', 'DOIPDUGD', 'DMCWKYVY', 'RQOHCYLT', 'OUWWVTRV', 'UPWAOMBR', 'FYHALKOP', 'XABWMARM', 'CJWXUIGO', 'CDNJSIMA', 'VWLELTGA', 'GNNAMESQ', 'BCFSHWYK', 'MZKHKGCP', 'XWBHGRPZ', 'PWFVMBCA', 'DCKFBUFN', 'WZAGOFYQ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDhXFJcUKEmj",
        "outputId": "cd3b118b-b897-4037-89c8-5854bd8bf149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "Data=pd.DataFrame({'Plaintext':x,'Ciphertext':y})\n",
        "Data.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plaintext</th>\n",
              "      <th>Ciphertext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BUEXRYKR</td>\n",
              "      <td>YRBUOVHO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BRPBGHIQ</td>\n",
              "      <td>YOMYDEFN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>QRBZJJHK</td>\n",
              "      <td>NOYWGGEH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BMBJPOYV</td>\n",
              "      <td>YJYGMLVS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WEOCDQWP</td>\n",
              "      <td>TBLZANTM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BMTDGQUZ</td>\n",
              "      <td>YJQADNRW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>FHZGPFJX</td>\n",
              "      <td>CEWDMCGU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GLINQEDO</td>\n",
              "      <td>DIFKNBAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LNKXSRYA</td>\n",
              "      <td>IKHUPOVX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>EWMUSNCP</td>\n",
              "      <td>BTJRPKZM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>YLGRVFFL</td>\n",
              "      <td>VIDOSCCI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>MNPIDNRM</td>\n",
              "      <td>JKMFAKOJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BEUVZYQH</td>\n",
              "      <td>YBRSWVNE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ADDEOZIO</td>\n",
              "      <td>XAABLWFL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>JQBEEFSS</td>\n",
              "      <td>GNYBBCPP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Plaintext Ciphertext\n",
              "0   BUEXRYKR   YRBUOVHO\n",
              "1   BRPBGHIQ   YOMYDEFN\n",
              "2   QRBZJJHK   NOYWGGEH\n",
              "3   BMBJPOYV   YJYGMLVS\n",
              "4   WEOCDQWP   TBLZANTM\n",
              "5   BMTDGQUZ   YJQADNRW\n",
              "6   FHZGPFJX   CEWDMCGU\n",
              "7   GLINQEDO   DIFKNBAL\n",
              "8   LNKXSRYA   IKHUPOVX\n",
              "9   EWMUSNCP   BTJRPKZM\n",
              "10  YLGRVFFL   VIDOSCCI\n",
              "11  MNPIDNRM   JKMFAKOJ\n",
              "12  BEUVZYQH   YBRSWVNE\n",
              "13  ADDEOZIO   XAABLWFL\n",
              "14  JQBEEFSS   GNYBBCPP"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb1rx_sNW2_Y"
      },
      "source": [
        "### Since Caesar Cipher is a Stream Cipher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvQRLZhmXkhR",
        "outputId": "f41d3aa9-c8fd-4640-bec8-9f8b8e45caf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "plaintext=[]\n",
        "ciphertext=[]\n",
        "for password in x:\n",
        "  for character in password:\n",
        "    plaintext.append(character)\n",
        "for Encrypted_password in y:\n",
        "  for character in Encrypted_password:\n",
        "    ciphertext.append(character)\n",
        "Data=pd.DataFrame({'Plaintext':plaintext,'Ciphertext':ciphertext})\n",
        "Data.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plaintext</th>\n",
              "      <th>Ciphertext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>X</td>\n",
              "      <td>U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>R</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Y</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>K</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>R</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>B</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>R</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>P</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>B</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>G</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>H</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Plaintext Ciphertext\n",
              "0          B          Y\n",
              "1          U          R\n",
              "2          E          B\n",
              "3          X          U\n",
              "4          R          O\n",
              "5          Y          V\n",
              "6          K          H\n",
              "7          R          O\n",
              "8          B          Y\n",
              "9          R          O\n",
              "10         P          M\n",
              "11         B          Y\n",
              "12         G          D\n",
              "13         H          E\n",
              "14         I          F"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKD7h79lpNlO"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBChraNfYir_"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctfHA7lYYslx",
        "outputId": "f874d326-43ef-4e0e-aa36-33950de8617c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "plaintext=LabelEncoder().fit_transform(plaintext).reshape(-1, 1)\n",
        "ciphertext=LabelEncoder().fit_transform(ciphertext).reshape(-1, 1)\n",
        "X=OneHotEncoder().fit_transform(plaintext).toarray()\n",
        "Y=OneHotEncoder().fit_transform(ciphertext).toarray()\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpsAtE50ceYp"
      },
      "source": [
        "### Splitting the Dataset - Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2QCsVWocdM2",
        "outputId": "ca94da2b-eea7-4e65-b630-05e35dd25d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(Y,X,test_size=0.2,random_state=0)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsTqMHKRf2dT"
      },
      "source": [
        "## Training the Shallow Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA70_1DOdGBp",
        "outputId": "ab05447c-47d5-4320-ee88-e3b1517c83f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "model_CC= models.Sequential()\n",
        "model_CC.add(layers.Dense(26, activation='relu',input_shape=(26,)))\n",
        "model_CC.add(layers.Dense(39, activation='relu'))\n",
        "model_CC.add(layers.Dense(26, activation='softmax'))\n",
        "model_CC.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 26)                702       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 39)                1053      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 26)                1040      \n",
            "=================================================================\n",
            "Total params: 2,795\n",
            "Trainable params: 2,795\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdrUUqrCf86y"
      },
      "source": [
        "EarlyStopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min',restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li8fxsnOeM8Q"
      },
      "source": [
        "model_CC.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zGCRWvfnbP",
        "outputId": "9346c5fe-1959-4525-a0f5-6b5b1d8274c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_CC.fit(x=X_train,y=Y_train,epochs=1000,batch_size=10,validation_split=0.1,callbacks=EarlyStopping)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 3.2670 - accuracy: 0.0347 - val_loss: 3.2782 - val_accuracy: 0.0312\n",
            "Epoch 2/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2575 - accuracy: 0.0417 - val_loss: 3.2697 - val_accuracy: 0.0312\n",
            "Epoch 3/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2488 - accuracy: 0.0729 - val_loss: 3.2613 - val_accuracy: 0.0312\n",
            "Epoch 4/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2402 - accuracy: 0.0729 - val_loss: 3.2527 - val_accuracy: 0.0312\n",
            "Epoch 5/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2317 - accuracy: 0.0729 - val_loss: 3.2444 - val_accuracy: 0.0312\n",
            "Epoch 6/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2230 - accuracy: 0.0729 - val_loss: 3.2358 - val_accuracy: 0.0312\n",
            "Epoch 7/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2143 - accuracy: 0.0729 - val_loss: 3.2272 - val_accuracy: 0.0312\n",
            "Epoch 8/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2058 - accuracy: 0.0868 - val_loss: 3.2191 - val_accuracy: 0.0625\n",
            "Epoch 9/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1974 - accuracy: 0.0972 - val_loss: 3.2112 - val_accuracy: 0.0625\n",
            "Epoch 10/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1894 - accuracy: 0.1215 - val_loss: 3.2035 - val_accuracy: 0.0938\n",
            "Epoch 11/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1811 - accuracy: 0.1424 - val_loss: 3.1955 - val_accuracy: 0.0938\n",
            "Epoch 12/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1726 - accuracy: 0.1528 - val_loss: 3.1872 - val_accuracy: 0.1250\n",
            "Epoch 13/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1640 - accuracy: 0.2882 - val_loss: 3.1793 - val_accuracy: 0.2500\n",
            "Epoch 14/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1553 - accuracy: 0.3194 - val_loss: 3.1711 - val_accuracy: 0.2812\n",
            "Epoch 15/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1466 - accuracy: 0.3715 - val_loss: 3.1633 - val_accuracy: 0.3125\n",
            "Epoch 16/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1378 - accuracy: 0.3889 - val_loss: 3.1551 - val_accuracy: 0.3125\n",
            "Epoch 17/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1288 - accuracy: 0.3889 - val_loss: 3.1470 - val_accuracy: 0.3125\n",
            "Epoch 18/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1198 - accuracy: 0.3889 - val_loss: 3.1386 - val_accuracy: 0.3125\n",
            "Epoch 19/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1106 - accuracy: 0.3889 - val_loss: 3.1301 - val_accuracy: 0.3125\n",
            "Epoch 20/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1012 - accuracy: 0.4062 - val_loss: 3.1216 - val_accuracy: 0.4062\n",
            "Epoch 21/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0913 - accuracy: 0.4236 - val_loss: 3.1122 - val_accuracy: 0.4062\n",
            "Epoch 22/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0812 - accuracy: 0.4236 - val_loss: 3.1032 - val_accuracy: 0.4062\n",
            "Epoch 23/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0713 - accuracy: 0.4514 - val_loss: 3.0943 - val_accuracy: 0.5000\n",
            "Epoch 24/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0611 - accuracy: 0.5035 - val_loss: 3.0846 - val_accuracy: 0.5938\n",
            "Epoch 25/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0506 - accuracy: 0.5833 - val_loss: 3.0746 - val_accuracy: 0.6250\n",
            "Epoch 26/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0399 - accuracy: 0.6250 - val_loss: 3.0647 - val_accuracy: 0.6250\n",
            "Epoch 27/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0287 - accuracy: 0.6250 - val_loss: 3.0544 - val_accuracy: 0.6250\n",
            "Epoch 28/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0172 - accuracy: 0.6389 - val_loss: 3.0440 - val_accuracy: 0.6562\n",
            "Epoch 29/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0057 - accuracy: 0.6667 - val_loss: 3.0335 - val_accuracy: 0.6562\n",
            "Epoch 30/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9940 - accuracy: 0.6667 - val_loss: 3.0222 - val_accuracy: 0.6562\n",
            "Epoch 31/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9816 - accuracy: 0.6701 - val_loss: 3.0109 - val_accuracy: 0.6562\n",
            "Epoch 32/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9692 - accuracy: 0.6875 - val_loss: 2.9997 - val_accuracy: 0.6875\n",
            "Epoch 33/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9566 - accuracy: 0.7014 - val_loss: 2.9882 - val_accuracy: 0.6875\n",
            "Epoch 34/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9434 - accuracy: 0.7014 - val_loss: 2.9755 - val_accuracy: 0.6875\n",
            "Epoch 35/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9297 - accuracy: 0.6806 - val_loss: 2.9630 - val_accuracy: 0.5938\n",
            "Epoch 36/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9159 - accuracy: 0.6667 - val_loss: 2.9503 - val_accuracy: 0.6562\n",
            "Epoch 37/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9020 - accuracy: 0.7500 - val_loss: 2.9378 - val_accuracy: 0.7812\n",
            "Epoch 38/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8879 - accuracy: 0.7569 - val_loss: 2.9246 - val_accuracy: 0.6875\n",
            "Epoch 39/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8738 - accuracy: 0.7569 - val_loss: 2.9117 - val_accuracy: 0.6875\n",
            "Epoch 40/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8590 - accuracy: 0.7396 - val_loss: 2.8980 - val_accuracy: 0.6875\n",
            "Epoch 41/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8442 - accuracy: 0.7396 - val_loss: 2.8843 - val_accuracy: 0.6875\n",
            "Epoch 42/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8292 - accuracy: 0.7396 - val_loss: 2.8702 - val_accuracy: 0.6875\n",
            "Epoch 43/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8137 - accuracy: 0.7396 - val_loss: 2.8556 - val_accuracy: 0.6875\n",
            "Epoch 44/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7979 - accuracy: 0.7396 - val_loss: 2.8413 - val_accuracy: 0.6875\n",
            "Epoch 45/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7822 - accuracy: 0.7465 - val_loss: 2.8264 - val_accuracy: 0.6875\n",
            "Epoch 46/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7659 - accuracy: 0.7396 - val_loss: 2.8112 - val_accuracy: 0.6875\n",
            "Epoch 47/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7494 - accuracy: 0.7917 - val_loss: 2.7963 - val_accuracy: 0.8438\n",
            "Epoch 48/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7327 - accuracy: 0.8507 - val_loss: 2.7806 - val_accuracy: 0.8438\n",
            "Epoch 49/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7154 - accuracy: 0.8438 - val_loss: 2.7644 - val_accuracy: 0.8438\n",
            "Epoch 50/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6976 - accuracy: 0.8646 - val_loss: 2.7479 - val_accuracy: 0.8438\n",
            "Epoch 51/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6797 - accuracy: 0.8576 - val_loss: 2.7306 - val_accuracy: 0.8438\n",
            "Epoch 52/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6615 - accuracy: 0.8681 - val_loss: 2.7137 - val_accuracy: 0.8438\n",
            "Epoch 53/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6432 - accuracy: 0.8646 - val_loss: 2.6962 - val_accuracy: 0.8438\n",
            "Epoch 54/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.6245 - accuracy: 0.8646 - val_loss: 2.6789 - val_accuracy: 0.8438\n",
            "Epoch 55/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6056 - accuracy: 0.8576 - val_loss: 2.6612 - val_accuracy: 0.8438\n",
            "Epoch 56/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5867 - accuracy: 0.8576 - val_loss: 2.6437 - val_accuracy: 0.8438\n",
            "Epoch 57/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5672 - accuracy: 0.8646 - val_loss: 2.6253 - val_accuracy: 0.8125\n",
            "Epoch 58/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5478 - accuracy: 0.8611 - val_loss: 2.6072 - val_accuracy: 0.8438\n",
            "Epoch 59/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5288 - accuracy: 0.8646 - val_loss: 2.5895 - val_accuracy: 0.8438\n",
            "Epoch 60/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5095 - accuracy: 0.8924 - val_loss: 2.5714 - val_accuracy: 0.8438\n",
            "Epoch 61/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4901 - accuracy: 0.8889 - val_loss: 2.5529 - val_accuracy: 0.8438\n",
            "Epoch 62/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4701 - accuracy: 0.8750 - val_loss: 2.5344 - val_accuracy: 0.8438\n",
            "Epoch 63/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4501 - accuracy: 0.8819 - val_loss: 2.5155 - val_accuracy: 0.8438\n",
            "Epoch 64/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.4301 - accuracy: 0.8889 - val_loss: 2.4965 - val_accuracy: 0.8438\n",
            "Epoch 65/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4095 - accuracy: 0.8750 - val_loss: 2.4770 - val_accuracy: 0.8125\n",
            "Epoch 66/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3889 - accuracy: 0.8750 - val_loss: 2.4573 - val_accuracy: 0.8438\n",
            "Epoch 67/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3675 - accuracy: 0.8889 - val_loss: 2.4365 - val_accuracy: 0.8438\n",
            "Epoch 68/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3457 - accuracy: 0.8819 - val_loss: 2.4160 - val_accuracy: 0.8438\n",
            "Epoch 69/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3240 - accuracy: 0.8750 - val_loss: 2.3955 - val_accuracy: 0.8438\n",
            "Epoch 70/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3021 - accuracy: 0.8819 - val_loss: 2.3745 - val_accuracy: 0.8438\n",
            "Epoch 71/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2796 - accuracy: 0.8924 - val_loss: 2.3531 - val_accuracy: 0.8438\n",
            "Epoch 72/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2569 - accuracy: 0.8924 - val_loss: 2.3319 - val_accuracy: 0.8438\n",
            "Epoch 73/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2345 - accuracy: 0.8924 - val_loss: 2.3106 - val_accuracy: 0.8438\n",
            "Epoch 74/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2119 - accuracy: 0.8924 - val_loss: 2.2890 - val_accuracy: 0.8438\n",
            "Epoch 75/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.1894 - accuracy: 0.8924 - val_loss: 2.2670 - val_accuracy: 0.8438\n",
            "Epoch 76/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1661 - accuracy: 0.8924 - val_loss: 2.2446 - val_accuracy: 0.8438\n",
            "Epoch 77/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1427 - accuracy: 0.8924 - val_loss: 2.2220 - val_accuracy: 0.8438\n",
            "Epoch 78/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1191 - accuracy: 0.8924 - val_loss: 2.1989 - val_accuracy: 0.8438\n",
            "Epoch 79/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0952 - accuracy: 0.8924 - val_loss: 2.1757 - val_accuracy: 0.8438\n",
            "Epoch 80/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0717 - accuracy: 0.9167 - val_loss: 2.1535 - val_accuracy: 0.8438\n",
            "Epoch 81/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0483 - accuracy: 0.9271 - val_loss: 2.1307 - val_accuracy: 0.8438\n",
            "Epoch 82/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.9306 - val_loss: 2.1083 - val_accuracy: 0.8438\n",
            "Epoch 83/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0002 - accuracy: 0.9306 - val_loss: 2.0840 - val_accuracy: 0.8438\n",
            "Epoch 84/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9758 - accuracy: 0.9236 - val_loss: 2.0610 - val_accuracy: 0.8438\n",
            "Epoch 85/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.9517 - accuracy: 0.9201 - val_loss: 2.0373 - val_accuracy: 0.8438\n",
            "Epoch 86/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9275 - accuracy: 0.9306 - val_loss: 2.0145 - val_accuracy: 0.8438\n",
            "Epoch 87/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9034 - accuracy: 0.9236 - val_loss: 1.9898 - val_accuracy: 0.8438\n",
            "Epoch 88/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8792 - accuracy: 0.9201 - val_loss: 1.9664 - val_accuracy: 0.8438\n",
            "Epoch 89/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8547 - accuracy: 0.9097 - val_loss: 1.9415 - val_accuracy: 0.8438\n",
            "Epoch 90/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8304 - accuracy: 0.9271 - val_loss: 1.9184 - val_accuracy: 0.8438\n",
            "Epoch 91/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8064 - accuracy: 0.9306 - val_loss: 1.8938 - val_accuracy: 0.8438\n",
            "Epoch 92/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7818 - accuracy: 0.9236 - val_loss: 1.8700 - val_accuracy: 0.8438\n",
            "Epoch 93/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7572 - accuracy: 0.9306 - val_loss: 1.8450 - val_accuracy: 0.8438\n",
            "Epoch 94/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7322 - accuracy: 0.9306 - val_loss: 1.8201 - val_accuracy: 0.8438\n",
            "Epoch 95/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7073 - accuracy: 0.9306 - val_loss: 1.7960 - val_accuracy: 0.8438\n",
            "Epoch 96/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.6827 - accuracy: 0.9306 - val_loss: 1.7718 - val_accuracy: 0.8438\n",
            "Epoch 97/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6581 - accuracy: 0.9306 - val_loss: 1.7474 - val_accuracy: 0.8438\n",
            "Epoch 98/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6333 - accuracy: 0.9306 - val_loss: 1.7217 - val_accuracy: 0.8438\n",
            "Epoch 99/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6085 - accuracy: 0.9514 - val_loss: 1.6964 - val_accuracy: 0.9688\n",
            "Epoch 100/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5836 - accuracy: 0.9583 - val_loss: 1.6717 - val_accuracy: 0.9688\n",
            "Epoch 101/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5587 - accuracy: 0.9583 - val_loss: 1.6467 - val_accuracy: 0.9688\n",
            "Epoch 102/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5342 - accuracy: 0.9583 - val_loss: 1.6211 - val_accuracy: 0.9688\n",
            "Epoch 103/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5094 - accuracy: 0.9583 - val_loss: 1.5957 - val_accuracy: 0.9688\n",
            "Epoch 104/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4848 - accuracy: 0.9583 - val_loss: 1.5718 - val_accuracy: 0.9688\n",
            "Epoch 105/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4596 - accuracy: 0.9583 - val_loss: 1.5457 - val_accuracy: 0.9688\n",
            "Epoch 106/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.4344 - accuracy: 0.9583 - val_loss: 1.5193 - val_accuracy: 0.9688\n",
            "Epoch 107/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4097 - accuracy: 0.9583 - val_loss: 1.4950 - val_accuracy: 0.9688\n",
            "Epoch 108/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3852 - accuracy: 0.9583 - val_loss: 1.4692 - val_accuracy: 0.9688\n",
            "Epoch 109/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3608 - accuracy: 0.9583 - val_loss: 1.4439 - val_accuracy: 0.9688\n",
            "Epoch 110/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3362 - accuracy: 0.9583 - val_loss: 1.4180 - val_accuracy: 0.9688\n",
            "Epoch 111/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3116 - accuracy: 0.9583 - val_loss: 1.3920 - val_accuracy: 0.9688\n",
            "Epoch 112/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2869 - accuracy: 0.9583 - val_loss: 1.3664 - val_accuracy: 0.9688\n",
            "Epoch 113/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2628 - accuracy: 0.9583 - val_loss: 1.3419 - val_accuracy: 0.9688\n",
            "Epoch 114/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2387 - accuracy: 0.9583 - val_loss: 1.3169 - val_accuracy: 0.9688\n",
            "Epoch 115/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2141 - accuracy: 0.9583 - val_loss: 1.2910 - val_accuracy: 0.9688\n",
            "Epoch 116/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1900 - accuracy: 0.9583 - val_loss: 1.2660 - val_accuracy: 0.9688\n",
            "Epoch 117/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1659 - accuracy: 0.9583 - val_loss: 1.2405 - val_accuracy: 0.9688\n",
            "Epoch 118/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1427 - accuracy: 0.9583 - val_loss: 1.2166 - val_accuracy: 0.9688\n",
            "Epoch 119/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1193 - accuracy: 0.9583 - val_loss: 1.1916 - val_accuracy: 0.9688\n",
            "Epoch 120/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0956 - accuracy: 0.9583 - val_loss: 1.1666 - val_accuracy: 0.9688\n",
            "Epoch 121/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0721 - accuracy: 0.9583 - val_loss: 1.1419 - val_accuracy: 0.9688\n",
            "Epoch 122/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0488 - accuracy: 0.9583 - val_loss: 1.1171 - val_accuracy: 0.9688\n",
            "Epoch 123/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0258 - accuracy: 0.9583 - val_loss: 1.0929 - val_accuracy: 0.9688\n",
            "Epoch 124/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0030 - accuracy: 0.9583 - val_loss: 1.0684 - val_accuracy: 0.9688\n",
            "Epoch 125/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9800 - accuracy: 0.9583 - val_loss: 1.0451 - val_accuracy: 0.9688\n",
            "Epoch 126/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9577 - accuracy: 0.9583 - val_loss: 1.0209 - val_accuracy: 0.9688\n",
            "Epoch 127/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9352 - accuracy: 0.9583 - val_loss: 0.9969 - val_accuracy: 0.9688\n",
            "Epoch 128/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9133 - accuracy: 0.9583 - val_loss: 0.9734 - val_accuracy: 0.9688\n",
            "Epoch 129/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8914 - accuracy: 0.9583 - val_loss: 0.9497 - val_accuracy: 0.9688\n",
            "Epoch 130/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8699 - accuracy: 0.9583 - val_loss: 0.9265 - val_accuracy: 0.9688\n",
            "Epoch 131/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8486 - accuracy: 0.9583 - val_loss: 0.9043 - val_accuracy: 0.9688\n",
            "Epoch 132/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8276 - accuracy: 0.9583 - val_loss: 0.8820 - val_accuracy: 0.9688\n",
            "Epoch 133/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8073 - accuracy: 0.9583 - val_loss: 0.8602 - val_accuracy: 0.9688\n",
            "Epoch 134/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7871 - accuracy: 0.9583 - val_loss: 0.8387 - val_accuracy: 0.9688\n",
            "Epoch 135/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7669 - accuracy: 0.9583 - val_loss: 0.8173 - val_accuracy: 0.9688\n",
            "Epoch 136/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.9583 - val_loss: 0.7960 - val_accuracy: 0.9688\n",
            "Epoch 137/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.9618 - val_loss: 0.7759 - val_accuracy: 0.9688\n",
            "Epoch 138/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7084 - accuracy: 0.9722 - val_loss: 0.7549 - val_accuracy: 0.9688\n",
            "Epoch 139/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.9792 - val_loss: 0.7339 - val_accuracy: 0.9688\n",
            "Epoch 140/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.9792 - val_loss: 0.7138 - val_accuracy: 0.9688\n",
            "Epoch 141/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.9792 - val_loss: 0.6941 - val_accuracy: 0.9688\n",
            "Epoch 142/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.9792 - val_loss: 0.6744 - val_accuracy: 0.9688\n",
            "Epoch 143/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.9792 - val_loss: 0.6549 - val_accuracy: 0.9688\n",
            "Epoch 144/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.9792 - val_loss: 0.6357 - val_accuracy: 0.9688\n",
            "Epoch 145/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.9792 - val_loss: 0.6167 - val_accuracy: 0.9688\n",
            "Epoch 146/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5645 - accuracy: 0.9792 - val_loss: 0.5987 - val_accuracy: 0.9688\n",
            "Epoch 147/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.9792 - val_loss: 0.5799 - val_accuracy: 0.9688\n",
            "Epoch 148/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.9792 - val_loss: 0.5612 - val_accuracy: 0.9688\n",
            "Epoch 149/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.9792 - val_loss: 0.5432 - val_accuracy: 0.9688\n",
            "Epoch 150/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.9792 - val_loss: 0.5251 - val_accuracy: 0.9688\n",
            "Epoch 151/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.9792 - val_loss: 0.5078 - val_accuracy: 0.9688\n",
            "Epoch 152/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.9792 - val_loss: 0.4916 - val_accuracy: 0.9688\n",
            "Epoch 153/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.9861 - val_loss: 0.4757 - val_accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 1.0000\n",
            "Epoch 162/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 1.0000\n",
            "Epoch 163/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3123 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2242 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1855 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 1.0000\n",
            "Epoch 180/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 1.0000\n",
            "Epoch 183/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1402 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1291 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 1.0000\n",
            "Epoch 195/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 1.0000\n",
            "Epoch 196/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 200/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.0568 - val_accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.7915e-04 - accuracy: 1.0000 - val_loss: 9.7649e-04 - val_accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.1254e-04 - accuracy: 1.0000 - val_loss: 9.0691e-04 - val_accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.4987e-04 - accuracy: 1.0000 - val_loss: 8.4290e-04 - val_accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.9250e-04 - accuracy: 1.0000 - val_loss: 7.8778e-04 - val_accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.3819e-04 - accuracy: 1.0000 - val_loss: 7.3091e-04 - val_accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 6.8913e-04 - accuracy: 1.0000 - val_loss: 6.8289e-04 - val_accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.4410e-04 - accuracy: 1.0000 - val_loss: 6.4438e-04 - val_accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.0183e-04 - accuracy: 1.0000 - val_loss: 5.9672e-04 - val_accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.5873e-04 - accuracy: 1.0000 - val_loss: 5.5282e-04 - val_accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.1971e-04 - accuracy: 1.0000 - val_loss: 5.1635e-04 - val_accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.8310e-04 - accuracy: 1.0000 - val_loss: 4.7831e-04 - val_accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.4885e-04 - accuracy: 1.0000 - val_loss: 4.4336e-04 - val_accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.1615e-04 - accuracy: 1.0000 - val_loss: 4.1165e-04 - val_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.8580e-04 - accuracy: 1.0000 - val_loss: 3.8038e-04 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.5689e-04 - accuracy: 1.0000 - val_loss: 3.5063e-04 - val_accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.3014e-04 - accuracy: 1.0000 - val_loss: 3.2388e-04 - val_accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0527e-04 - accuracy: 1.0000 - val_loss: 2.9992e-04 - val_accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8316e-04 - accuracy: 1.0000 - val_loss: 2.7882e-04 - val_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6201e-04 - accuracy: 1.0000 - val_loss: 2.5651e-04 - val_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4242e-04 - accuracy: 1.0000 - val_loss: 2.3768e-04 - val_accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2457e-04 - accuracy: 1.0000 - val_loss: 2.1963e-04 - val_accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0798e-04 - accuracy: 1.0000 - val_loss: 2.0436e-04 - val_accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9279e-04 - accuracy: 1.0000 - val_loss: 1.8774e-04 - val_accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7825e-04 - accuracy: 1.0000 - val_loss: 1.7342e-04 - val_accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6470e-04 - accuracy: 1.0000 - val_loss: 1.6042e-04 - val_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5262e-04 - accuracy: 1.0000 - val_loss: 1.4893e-04 - val_accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4100e-04 - accuracy: 1.0000 - val_loss: 1.3752e-04 - val_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3027e-04 - accuracy: 1.0000 - val_loss: 1.2735e-04 - val_accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2084e-04 - accuracy: 1.0000 - val_loss: 1.1771e-04 - val_accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1136e-04 - accuracy: 1.0000 - val_loss: 1.0843e-04 - val_accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0286e-04 - accuracy: 1.0000 - val_loss: 1.0026e-04 - val_accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.4875e-05 - accuracy: 1.0000 - val_loss: 9.2210e-05 - val_accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.7477e-05 - accuracy: 1.0000 - val_loss: 8.5477e-05 - val_accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.0635e-05 - accuracy: 1.0000 - val_loss: 7.8372e-05 - val_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.4121e-05 - accuracy: 1.0000 - val_loss: 7.1908e-05 - val_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.8387e-05 - accuracy: 1.0000 - val_loss: 6.6616e-05 - val_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.3027e-05 - accuracy: 1.0000 - val_loss: 6.1253e-05 - val_accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.8141e-05 - accuracy: 1.0000 - val_loss: 5.6222e-05 - val_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.3536e-05 - accuracy: 1.0000 - val_loss: 5.1939e-05 - val_accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.9269e-05 - accuracy: 1.0000 - val_loss: 4.7779e-05 - val_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.5257e-05 - accuracy: 1.0000 - val_loss: 4.3622e-05 - val_accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.1463e-05 - accuracy: 1.0000 - val_loss: 3.9976e-05 - val_accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.8087e-05 - accuracy: 1.0000 - val_loss: 3.6881e-05 - val_accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.5020e-05 - accuracy: 1.0000 - val_loss: 3.3670e-05 - val_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2139e-05 - accuracy: 1.0000 - val_loss: 3.0910e-05 - val_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9532e-05 - accuracy: 1.0000 - val_loss: 2.8299e-05 - val_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7040e-05 - accuracy: 1.0000 - val_loss: 2.5941e-05 - val_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4902e-05 - accuracy: 1.0000 - val_loss: 2.4053e-05 - val_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2869e-05 - accuracy: 1.0000 - val_loss: 2.1922e-05 - val_accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1019e-05 - accuracy: 1.0000 - val_loss: 2.0026e-05 - val_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9246e-05 - accuracy: 1.0000 - val_loss: 1.8317e-05 - val_accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7702e-05 - accuracy: 1.0000 - val_loss: 1.6968e-05 - val_accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6252e-05 - accuracy: 1.0000 - val_loss: 1.5430e-05 - val_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4963e-05 - accuracy: 1.0000 - val_loss: 1.4219e-05 - val_accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3759e-05 - accuracy: 1.0000 - val_loss: 1.3064e-05 - val_accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2646e-05 - accuracy: 1.0000 - val_loss: 1.2070e-05 - val_accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1633e-05 - accuracy: 1.0000 - val_loss: 1.1004e-05 - val_accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0679e-05 - accuracy: 1.0000 - val_loss: 1.0106e-05 - val_accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.7820e-06 - accuracy: 1.0000 - val_loss: 9.2646e-06 - val_accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.9584e-06 - accuracy: 1.0000 - val_loss: 8.4823e-06 - val_accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.2551e-06 - accuracy: 1.0000 - val_loss: 7.8416e-06 - val_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.6065e-06 - accuracy: 1.0000 - val_loss: 7.1487e-06 - val_accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.9761e-06 - accuracy: 1.0000 - val_loss: 6.5639e-06 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.4161e-06 - accuracy: 1.0000 - val_loss: 5.9865e-06 - val_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.8813e-06 - accuracy: 1.0000 - val_loss: 5.4873e-06 - val_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.3880e-06 - accuracy: 1.0000 - val_loss: 5.0812e-06 - val_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.9807e-06 - accuracy: 1.0000 - val_loss: 4.6119e-06 - val_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.5783e-06 - accuracy: 1.0000 - val_loss: 4.2878e-06 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.2315e-06 - accuracy: 1.0000 - val_loss: 3.9339e-06 - val_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.8946e-06 - accuracy: 1.0000 - val_loss: 3.6247e-06 - val_accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.6036e-06 - accuracy: 1.0000 - val_loss: 3.3788e-06 - val_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.3130e-06 - accuracy: 1.0000 - val_loss: 3.0845e-06 - val_accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0696e-06 - accuracy: 1.0000 - val_loss: 2.8536e-06 - val_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8366e-06 - accuracy: 1.0000 - val_loss: 2.6189e-06 - val_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6276e-06 - accuracy: 1.0000 - val_loss: 2.4289e-06 - val_accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4442e-06 - accuracy: 1.0000 - val_loss: 2.2575e-06 - val_accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2509e-06 - accuracy: 1.0000 - val_loss: 2.0824e-06 - val_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0878e-06 - accuracy: 1.0000 - val_loss: 1.9595e-06 - val_accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9508e-06 - accuracy: 1.0000 - val_loss: 1.8403e-06 - val_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8121e-06 - accuracy: 1.0000 - val_loss: 1.6727e-06 - val_accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6842e-06 - accuracy: 1.0000 - val_loss: 1.5460e-06 - val_accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5696e-06 - accuracy: 1.0000 - val_loss: 1.4566e-06 - val_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4736e-06 - accuracy: 1.0000 - val_loss: 1.3746e-06 - val_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3697e-06 - accuracy: 1.0000 - val_loss: 1.2629e-06 - val_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2778e-06 - accuracy: 1.0000 - val_loss: 1.1846e-06 - val_accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1867e-06 - accuracy: 1.0000 - val_loss: 1.0952e-06 - val_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1217e-06 - accuracy: 1.0000 - val_loss: 1.0282e-06 - val_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0497e-06 - accuracy: 1.0000 - val_loss: 9.8720e-07 - val_accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.9341e-07 - accuracy: 1.0000 - val_loss: 9.3505e-07 - val_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.4581e-07 - accuracy: 1.0000 - val_loss: 8.6799e-07 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 8.9531e-07 - accuracy: 1.0000 - val_loss: 8.2701e-07 - val_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.3571e-07 - accuracy: 1.0000 - val_loss: 7.7858e-07 - val_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.9804e-07 - accuracy: 1.0000 - val_loss: 7.5623e-07 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.6493e-07 - accuracy: 1.0000 - val_loss: 7.3388e-07 - val_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.1939e-07 - accuracy: 1.0000 - val_loss: 6.9663e-07 - val_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.7511e-07 - accuracy: 1.0000 - val_loss: 6.4447e-07 - val_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.3827e-07 - accuracy: 1.0000 - val_loss: 6.1095e-07 - val_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.0308e-07 - accuracy: 1.0000 - val_loss: 5.5507e-07 - val_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.6873e-07 - accuracy: 1.0000 - val_loss: 5.2899e-07 - val_accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.3810e-07 - accuracy: 1.0000 - val_loss: 4.8801e-07 - val_accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.1326e-07 - accuracy: 1.0000 - val_loss: 4.7684e-07 - val_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.8553e-07 - accuracy: 1.0000 - val_loss: 4.4331e-07 - val_accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.5987e-07 - accuracy: 1.0000 - val_loss: 4.2096e-07 - val_accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.3627e-07 - accuracy: 1.0000 - val_loss: 4.1351e-07 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.2675e-07 - accuracy: 1.0000 - val_loss: 4.0606e-07 - val_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.1433e-07 - accuracy: 1.0000 - val_loss: 3.9116e-07 - val_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.9695e-07 - accuracy: 1.0000 - val_loss: 3.6880e-07 - val_accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.6384e-07 - accuracy: 1.0000 - val_loss: 3.4645e-07 - val_accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.5142e-07 - accuracy: 1.0000 - val_loss: 3.3528e-07 - val_accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.3528e-07 - accuracy: 1.0000 - val_loss: 3.0547e-07 - val_accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1872e-07 - accuracy: 1.0000 - val_loss: 3.0175e-07 - val_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0382e-07 - accuracy: 1.0000 - val_loss: 2.6822e-07 - val_accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9223e-07 - accuracy: 1.0000 - val_loss: 2.5332e-07 - val_accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7981e-07 - accuracy: 1.0000 - val_loss: 2.4959e-07 - val_accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7236e-07 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6325e-07 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5456e-07 - accuracy: 1.0000 - val_loss: 2.3469e-07 - val_accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4959e-07 - accuracy: 1.0000 - val_loss: 2.3097e-07 - val_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4007e-07 - accuracy: 1.0000 - val_loss: 2.2724e-07 - val_accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3262e-07 - accuracy: 1.0000 - val_loss: 2.2352e-07 - val_accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1855e-07 - accuracy: 1.0000 - val_loss: 2.1607e-07 - val_accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0406e-07 - accuracy: 1.0000 - val_loss: 1.8999e-07 - val_accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9578e-07 - accuracy: 1.0000 - val_loss: 1.8999e-07 - val_accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9330e-07 - accuracy: 1.0000 - val_loss: 1.8254e-07 - val_accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8751e-07 - accuracy: 1.0000 - val_loss: 1.7136e-07 - val_accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8544e-07 - accuracy: 1.0000 - val_loss: 1.7136e-07 - val_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8006e-07 - accuracy: 1.0000 - val_loss: 1.6391e-07 - val_accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7467e-07 - accuracy: 1.0000 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6102e-07 - accuracy: 1.0000 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5688e-07 - accuracy: 1.0000 - val_loss: 1.5274e-07 - val_accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6102e-07 - accuracy: 1.0000 - val_loss: 1.5274e-07 - val_accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5398e-07 - accuracy: 1.0000 - val_loss: 1.5274e-07 - val_accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5522e-07 - accuracy: 1.0000 - val_loss: 1.4529e-07 - val_accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4984e-07 - accuracy: 1.0000 - val_loss: 1.4529e-07 - val_accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4529e-07 - accuracy: 1.0000 - val_loss: 1.3039e-07 - val_accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4156e-07 - accuracy: 1.0000 - val_loss: 1.1548e-07 - val_accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4280e-07 - accuracy: 1.0000 - val_loss: 1.2293e-07 - val_accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4197e-07 - accuracy: 1.0000 - val_loss: 1.2293e-07 - val_accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3866e-07 - accuracy: 1.0000 - val_loss: 1.0803e-07 - val_accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3494e-07 - accuracy: 1.0000 - val_loss: 1.3411e-07 - val_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3784e-07 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2914e-07 - accuracy: 1.0000 - val_loss: 9.6858e-08 - val_accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2004e-07 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1176e-07 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0638e-07 - accuracy: 1.0000 - val_loss: 1.0058e-07 - val_accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0182e-07 - accuracy: 1.0000 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0265e-07 - accuracy: 1.0000 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.9407e-08 - accuracy: 1.0000 - val_loss: 9.3132e-08 - val_accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.9407e-08 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.0649e-08 - accuracy: 1.0000 - val_loss: 1.0058e-07 - val_accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.8579e-08 - accuracy: 1.0000 - val_loss: 7.0781e-08 - val_accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.6096e-08 - accuracy: 1.0000 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.5268e-08 - accuracy: 1.0000 - val_loss: 8.5682e-08 - val_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.1542e-08 - accuracy: 1.0000 - val_loss: 9.3132e-08 - val_accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.4506e-08 - accuracy: 1.0000 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.5748e-08 - accuracy: 1.0000 - val_loss: 7.8231e-08 - val_accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.2022e-08 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.4986e-08 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.8711e-08 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.8297e-08 - accuracy: 1.0000 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.5879e-08 - accuracy: 1.0000 - val_loss: 6.7055e-08 - val_accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.0019e-08 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.2982e-08 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.4638e-08 - accuracy: 1.0000 - val_loss: 5.5879e-08 - val_accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.0084e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.0084e-08 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.2982e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.3396e-08 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.9671e-08 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.0978e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.0978e-08 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.0150e-08 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.0564e-08 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.1806e-08 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.2220e-08 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.8495e-08 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.0564e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.7253e-08 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.7253e-08 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.2220e-08 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2700e-08 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.5183e-08 - accuracy: 1.0000 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2700e-08 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2286e-08 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.5183e-08 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0630e-08 - accuracy: 1.0000 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0216e-08 - accuracy: 1.0000 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0630e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1044e-08 - accuracy: 1.0000 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "23/29 [======================>.......] - ETA: 0s - loss: 3.4208e-08 - accuracy: 1.0000Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2286e-08 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
            "Epoch 00465: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f283457bfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzk_veNghbk9"
      },
      "source": [
        "History = model_CC.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H11YUWRKhjX8",
        "outputId": "2e99d979-a827-4d34-c0e1-44733eb60f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(History.history['accuracy'])\n",
        "plt.title('Accuracy VS Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gciWe5pShw_w",
        "outputId": "64c60cc3-6cd5-4fc8-8793-142309b0cdf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(History.history['loss'])\n",
        "plt.title('Loss VS Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKqDI_Kkpjq0"
      },
      "source": [
        "## Testing the Shallow Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crKdmviAlwXF",
        "outputId": "072803d1-1622-4717-cd02-7b9b7df41ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "Loss,Accuracy=model_CC.evaluate(X_test,Y_test,verbose=1)\n",
        "print('Accuracy: ',Accuracy)\n",
        "print('Loss: ',Loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 2ms/step - loss: 2.8312e-08 - accuracy: 1.0000\n",
            "Accuracy:  1.0\n",
            "Loss:  2.831220413668234e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDDayESX2bTx"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gemhjnzb2i35"
      },
      "source": [
        "Name='Model 1.3 - CC 39'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsRhW0Dk2u9j"
      },
      "source": [
        "Name=Name + ' - ' + str(datetime.datetime.now()) + '.h5'\n",
        "model_CC.save('/content/drive/My Drive/AI Breaks Cryptography/Models/'+Name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K5rG9B4iRDB"
      },
      "source": [
        "## Decoding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32GziM3xp6wq",
        "outputId": "da7d2214-b87c-4bad-d9bd-238c1d728bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "Categories=[i for i in CHOICES]\n",
        "Label_Encoding=LabelEncoder().fit_transform(Categories).reshape(-1,1)\n",
        "One_Hot_Encoding=OneHotEncoder().fit_transform(Label_Encoding).toarray()\n",
        "Categories_Dictionary={Categories[i]:One_Hot_Encoding[i] for i in range(len(Categories))}\n",
        "Categories_Dictionary_Reverse={tuple(One_Hot_Encoding[i]):Categories[i] for i in range(len(Categories))}\n",
        "print(Categories_Dictionary)\n",
        "print(Categories_Dictionary_Reverse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'A': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'B': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'C': array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'D': array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'E': array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'F': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'G': array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'H': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'I': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'J': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'K': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'L': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'M': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'N': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'O': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'P': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'Q': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'R': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       1., 0., 0., 0., 0., 0., 0., 0., 0.]), 'S': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 1., 0., 0., 0., 0., 0., 0., 0.]), 'T': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'U': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 1., 0., 0., 0., 0., 0.]), 'V': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'W': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 1., 0., 0., 0.]), 'X': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 1., 0., 0.]), 'Y': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 1., 0.]), 'Z': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 1.])}\n",
            "{(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'A', (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'B', (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'C', (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'D', (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'E', (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'F', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'G', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'H', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'I', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'J', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'K', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'L', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'M', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'N', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'O', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'P', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'Q', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'R', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'S', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'T', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'U', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0): 'V', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0): 'W', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0): 'X', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0): 'Y', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0): 'Z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAsnwgBXiPLu"
      },
      "source": [
        "def Decode(character,Categories_Dictionary_Reverse=Categories_Dictionary_Reverse):\n",
        "  #print(np.array(Categories_Dictionary[character]).shape)\n",
        "  prediction=model_CC.predict(np.array(Categories_Dictionary[character]).reshape(1,26))\n",
        "  prediction=prediction>=prediction.max()\n",
        "  #print(prediction)\n",
        "  temp=[0.0 for i in range(26)]\n",
        "  for i in range(len(prediction[0])):\n",
        "    if prediction[0][i]==True:\n",
        "      temp[i]=1\n",
        "  return Categories_Dictionary_Reverse[tuple(temp)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8yoDMSTqqWO",
        "outputId": "36d6841a-3652-46fb-8c36-12ff8965e6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "character='G'\n",
        "print(character)\n",
        "print(Decode(character))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "G\n",
            "J\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMOLtyxzfVxs"
      },
      "source": [
        "## AI Based Decryption of Caesar Cipher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEnxRSI1ebzQ",
        "outputId": "328733ac-0c8c-4417-a439-6f53cc53a078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "MESSAGE=\"CHRISTEEN T JOSE\"\n",
        "MESSAGE=MESSAGE.upper()\n",
        "print(\"\\t\\tOriginal Message:\\t\\t\\t\\t\",MESSAGE)\n",
        "ENCRYPTED_MESSAGE=CaesarCipher_encryption(MESSAGE,KEY)\n",
        "print(\"\\n\\n\\t\\tMessage after Encryption using Caesar Cipher:\\t\",ENCRYPTED_MESSAGE)\n",
        "#print(\"Key used for Encryption: \",KEY)\n",
        "DECRYPTED_MESSAGE=''\n",
        "for i in ENCRYPTED_MESSAGE:\n",
        "  if i==' ':\n",
        "    DECRYPTED_MESSAGE+=i\n",
        "  else:\n",
        "    DECRYPTED_MESSAGE+=Decode(i)\n",
        "print(\"\\n\\n\\t\\tMessage after AI based Decryption:\\t\\t\",DECRYPTED_MESSAGE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tOriginal Message:\t\t\t\t CHRISTEEN T JOSE\n",
            "\n",
            "\n",
            "\t\tMessage after Encryption using Caesar Cipher:\t ZEOFPQBBK Q GLPB\n",
            "\n",
            "\n",
            "\t\tMessage after AI based Decryption:\t\t CHRISTEEN T JOSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoDll0HmzEcG"
      },
      "source": [
        "# ROT13 Cipher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR1xBSnFzEcI"
      },
      "source": [
        "## Known-Plaintext Attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xheJltRDzEcS"
      },
      "source": [
        "### Password Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kIOlbg-zEcT"
      },
      "source": [
        "PASSWORD_SIZE=8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQJdKCoxzEca"
      },
      "source": [
        "### Dataset Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPSW4JQ0zEcb"
      },
      "source": [
        "DATASET_SIZE=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OJYOcovzEch"
      },
      "source": [
        "### Generation of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImWliuCrzEci",
        "outputId": "2e451900-01c2-465f-ed17-f8cb1136dd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "CHOICES=CaesarCipher_characterset()\n",
        "CHOICES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdx8jN5DzEco",
        "outputId": "689ec88c-1365-4140-dae4-3bd13b15a526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for i in range(DATASET_SIZE):\n",
        "  temp=''\n",
        "  for j in range(PASSWORD_SIZE):\n",
        "    temp+=random.choice(CHOICES)\n",
        "  x.append(temp)\n",
        "  y.append(ROT13(temp))\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['BYPDOSFR', 'ZYYKRSBZ', 'NGIKKOGV', 'HYTFVPRC', 'TEWDZTYI', 'QZSMMPHT', 'TMZTINKC', 'TELZRJET', 'ATVDJEYO', 'IFCOWNEH', 'GLBCVSOJ', 'FYSVHUUO', 'KYTLSYTL', 'JDBZKIIM', 'JRCLQEOC', 'LEMAHPLM', 'SUTFJFGK', 'RYWLICIB', 'DISYBXMW', 'DXCWWETW', 'FTUEQLXB', 'YTFPCSZI', 'DWAOVPSP', 'EBOQYAHF', 'HZBABQXF', 'BMQZPNIV', 'BQGVBSKG', 'PILIQYXC', 'HSJZEUXI', 'YZGYBNJP', 'DWCDLTRU', 'UPVJTOIL', 'BWTWROKA', 'MBJREGUW', 'LIDZNHYS', 'WNMTGESC', 'XHXZZJLH', 'DGNPPJNA', 'BMTWEKOS', 'URORSTMB', 'HRSKBFFX', 'XIDPQOZX', 'OBYAOHAH', 'YHPDYSJS', 'FYXCYHEF', 'BUCEYXFI', 'NDAAIIUD', 'CQFDVNDW', 'ZCMMZSBI', 'KDTWJZFY']\n",
            "['OLCQBFSE', 'MLLXEFOM', 'ATVXXBTI', 'ULGSICEP', 'GRJQMGLV', 'DMFZZCUG', 'GZMGVAXP', 'GRYMEWRG', 'NGIQWRLB', 'VSPBJARU', 'TYOPIFBW', 'SLFIUHHB', 'XLGYFLGY', 'WQOMXVVZ', 'WEPYDRBP', 'YRZNUCYZ', 'FHGSWSTX', 'ELJYVPVO', 'QVFLOKZJ', 'QKPJJRGJ', 'SGHRDYKO', 'LGSCPFMV', 'QJNBICFC', 'ROBDLNUS', 'UMONODKS', 'OZDMCAVI', 'ODTIOFXT', 'CVYVDLKP', 'UFWMRHKV', 'LMTLOAWC', 'QJPQYGEH', 'HCIWGBVY', 'OJGJEBXN', 'ZOWERTHJ', 'YVQMAULF', 'JAZGTRFP', 'KUKMMWYU', 'QTACCWAN', 'OZGJRXBF', 'HEBEFGZO', 'UEFXOSSK', 'KVQCDBMK', 'BOLNBUNU', 'LUCQLFWF', 'SLKPLURS', 'OHPRLKSV', 'AQNNVVHQ', 'PDSQIAQJ', 'MPZZMFOV', 'XQGJWMSL']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jDpNUgizEct",
        "outputId": "cde6c08c-fcf5-47d5-de5b-09675ed555e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "Data=pd.DataFrame({'Plaintext':x,'Ciphertext':y})\n",
        "Data.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plaintext</th>\n",
              "      <th>Ciphertext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BYPDOSFR</td>\n",
              "      <td>OLCQBFSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ZYYKRSBZ</td>\n",
              "      <td>MLLXEFOM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NGIKKOGV</td>\n",
              "      <td>ATVXXBTI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HYTFVPRC</td>\n",
              "      <td>ULGSICEP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEWDZTYI</td>\n",
              "      <td>GRJQMGLV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>QZSMMPHT</td>\n",
              "      <td>DMFZZCUG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TMZTINKC</td>\n",
              "      <td>GZMGVAXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TELZRJET</td>\n",
              "      <td>GRYMEWRG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ATVDJEYO</td>\n",
              "      <td>NGIQWRLB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>IFCOWNEH</td>\n",
              "      <td>VSPBJARU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>GLBCVSOJ</td>\n",
              "      <td>TYOPIFBW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>FYSVHUUO</td>\n",
              "      <td>SLFIUHHB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>KYTLSYTL</td>\n",
              "      <td>XLGYFLGY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>JDBZKIIM</td>\n",
              "      <td>WQOMXVVZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>JRCLQEOC</td>\n",
              "      <td>WEPYDRBP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Plaintext Ciphertext\n",
              "0   BYPDOSFR   OLCQBFSE\n",
              "1   ZYYKRSBZ   MLLXEFOM\n",
              "2   NGIKKOGV   ATVXXBTI\n",
              "3   HYTFVPRC   ULGSICEP\n",
              "4   TEWDZTYI   GRJQMGLV\n",
              "5   QZSMMPHT   DMFZZCUG\n",
              "6   TMZTINKC   GZMGVAXP\n",
              "7   TELZRJET   GRYMEWRG\n",
              "8   ATVDJEYO   NGIQWRLB\n",
              "9   IFCOWNEH   VSPBJARU\n",
              "10  GLBCVSOJ   TYOPIFBW\n",
              "11  FYSVHUUO   SLFIUHHB\n",
              "12  KYTLSYTL   XLGYFLGY\n",
              "13  JDBZKIIM   WQOMXVVZ\n",
              "14  JRCLQEOC   WEPYDRBP"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE20axmhzEcy"
      },
      "source": [
        "### Since ROT13 is a Stream Cipher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHhAlFpzzEcz",
        "outputId": "21df8a44-5650-41c7-fc17-28153666ca93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "plaintext=[]\n",
        "ciphertext=[]\n",
        "for password in x:\n",
        "  for character in password:\n",
        "    plaintext.append(character)\n",
        "for Encrypted_password in y:\n",
        "  for character in Encrypted_password:\n",
        "    ciphertext.append(character)\n",
        "Data=pd.DataFrame({'Plaintext':plaintext,'Ciphertext':ciphertext})\n",
        "Data.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plaintext</th>\n",
              "      <th>Ciphertext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Y</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>F</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>R</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Z</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Y</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Y</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>K</td>\n",
              "      <td>X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>R</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>B</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Plaintext Ciphertext\n",
              "0          B          O\n",
              "1          Y          L\n",
              "2          P          C\n",
              "3          D          Q\n",
              "4          O          B\n",
              "5          S          F\n",
              "6          F          S\n",
              "7          R          E\n",
              "8          Z          M\n",
              "9          Y          L\n",
              "10         Y          L\n",
              "11         K          X\n",
              "12         R          E\n",
              "13         S          F\n",
              "14         B          O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ0nsF5MzEc4"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7B8XlBezEc5"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsBW44KrzEc6",
        "outputId": "d2b24fa8-441b-4930-9096-4dc3ccb18a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "plaintext=LabelEncoder().fit_transform(plaintext).reshape(-1, 1)\n",
        "ciphertext=LabelEncoder().fit_transform(ciphertext).reshape(-1, 1)\n",
        "X=OneHotEncoder().fit_transform(plaintext).toarray()\n",
        "Y=OneHotEncoder().fit_transform(ciphertext).toarray()\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laHhuHEXzEc_"
      },
      "source": [
        "### Splitting the Dataset - Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyzi1IRpzEdA",
        "outputId": "2b692d37-7050-4fad-be4b-fd65f6b9be5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(Y,X,test_size=0.2,random_state=0)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NJrNBZRzEdF"
      },
      "source": [
        "## Training the Shallow Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryRo7yE5zEdG",
        "outputId": "a0606ff9-6c59-447e-e7fc-c71d5f0533f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "model_ROT13= models.Sequential()\n",
        "model_ROT13.add(layers.Dense(26, activation='relu',input_shape=(26,)))\n",
        "model_ROT13.add(layers.Dense(39, activation='relu'))\n",
        "model_ROT13.add(layers.Dense(26, activation='softmax'))\n",
        "model_ROT13.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 26)                702       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 39)                1053      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 26)                1040      \n",
            "=================================================================\n",
            "Total params: 2,795\n",
            "Trainable params: 2,795\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utENcvrozEdL"
      },
      "source": [
        "EarlyStopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min',restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b5q_b8IzEdQ"
      },
      "source": [
        "model_ROT13.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUayQcxzzEdU",
        "outputId": "2d037fad-05b9-44db-d6ff-83a15e22ab85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_ROT13.fit(x=X_train,y=Y_train,epochs=1000,batch_size=10,validation_split=0.1,callbacks=EarlyStopping)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3.2639 - accuracy: 0.1111 - val_loss: 3.2612 - val_accuracy: 0.1562\n",
            "Epoch 2/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2534 - accuracy: 0.1111 - val_loss: 3.2516 - val_accuracy: 0.1562\n",
            "Epoch 3/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2438 - accuracy: 0.1111 - val_loss: 3.2422 - val_accuracy: 0.1562\n",
            "Epoch 4/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2343 - accuracy: 0.1111 - val_loss: 3.2329 - val_accuracy: 0.1562\n",
            "Epoch 5/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.2248 - accuracy: 0.1389 - val_loss: 3.2234 - val_accuracy: 0.2188\n",
            "Epoch 6/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2154 - accuracy: 0.1875 - val_loss: 3.2138 - val_accuracy: 0.2188\n",
            "Epoch 7/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2058 - accuracy: 0.1875 - val_loss: 3.2041 - val_accuracy: 0.2188\n",
            "Epoch 8/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1960 - accuracy: 0.2326 - val_loss: 3.1944 - val_accuracy: 0.2188\n",
            "Epoch 9/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1863 - accuracy: 0.2326 - val_loss: 3.1848 - val_accuracy: 0.2188\n",
            "Epoch 10/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1768 - accuracy: 0.2326 - val_loss: 3.1752 - val_accuracy: 0.2188\n",
            "Epoch 11/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1673 - accuracy: 0.2326 - val_loss: 3.1656 - val_accuracy: 0.2188\n",
            "Epoch 12/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1576 - accuracy: 0.2569 - val_loss: 3.1555 - val_accuracy: 0.2812\n",
            "Epoch 13/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1478 - accuracy: 0.2882 - val_loss: 3.1453 - val_accuracy: 0.3438\n",
            "Epoch 14/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1380 - accuracy: 0.3194 - val_loss: 3.1353 - val_accuracy: 0.3438\n",
            "Epoch 15/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1278 - accuracy: 0.3542 - val_loss: 3.1245 - val_accuracy: 0.3438\n",
            "Epoch 16/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1173 - accuracy: 0.3542 - val_loss: 3.1135 - val_accuracy: 0.3438\n",
            "Epoch 17/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1065 - accuracy: 0.3542 - val_loss: 3.1021 - val_accuracy: 0.4375\n",
            "Epoch 18/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0956 - accuracy: 0.4097 - val_loss: 3.0910 - val_accuracy: 0.4375\n",
            "Epoch 19/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0845 - accuracy: 0.4688 - val_loss: 3.0794 - val_accuracy: 0.5312\n",
            "Epoch 20/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0733 - accuracy: 0.5069 - val_loss: 3.0679 - val_accuracy: 0.5312\n",
            "Epoch 21/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0620 - accuracy: 0.5069 - val_loss: 3.0561 - val_accuracy: 0.5312\n",
            "Epoch 22/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0506 - accuracy: 0.5104 - val_loss: 3.0445 - val_accuracy: 0.6562\n",
            "Epoch 23/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0391 - accuracy: 0.5417 - val_loss: 3.0327 - val_accuracy: 0.6562\n",
            "Epoch 24/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.0272 - accuracy: 0.5417 - val_loss: 3.0205 - val_accuracy: 0.6562\n",
            "Epoch 25/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.0149 - accuracy: 0.5417 - val_loss: 3.0076 - val_accuracy: 0.6562\n",
            "Epoch 26/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0024 - accuracy: 0.5417 - val_loss: 2.9947 - val_accuracy: 0.6562\n",
            "Epoch 27/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9898 - accuracy: 0.5521 - val_loss: 2.9814 - val_accuracy: 0.6875\n",
            "Epoch 28/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9768 - accuracy: 0.5833 - val_loss: 2.9683 - val_accuracy: 0.6875\n",
            "Epoch 29/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9635 - accuracy: 0.5833 - val_loss: 2.9546 - val_accuracy: 0.6875\n",
            "Epoch 30/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9503 - accuracy: 0.5833 - val_loss: 2.9413 - val_accuracy: 0.6875\n",
            "Epoch 31/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9371 - accuracy: 0.5833 - val_loss: 2.9277 - val_accuracy: 0.6875\n",
            "Epoch 32/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9234 - accuracy: 0.5833 - val_loss: 2.9130 - val_accuracy: 0.6875\n",
            "Epoch 33/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9091 - accuracy: 0.5833 - val_loss: 2.8983 - val_accuracy: 0.6875\n",
            "Epoch 34/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8948 - accuracy: 0.5833 - val_loss: 2.8837 - val_accuracy: 0.6875\n",
            "Epoch 35/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8803 - accuracy: 0.5833 - val_loss: 2.8687 - val_accuracy: 0.6875\n",
            "Epoch 36/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8653 - accuracy: 0.6215 - val_loss: 2.8534 - val_accuracy: 0.7188\n",
            "Epoch 37/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8501 - accuracy: 0.6701 - val_loss: 2.8381 - val_accuracy: 0.7500\n",
            "Epoch 38/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8347 - accuracy: 0.6875 - val_loss: 2.8224 - val_accuracy: 0.7500\n",
            "Epoch 39/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8191 - accuracy: 0.7083 - val_loss: 2.8063 - val_accuracy: 0.8125\n",
            "Epoch 40/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8032 - accuracy: 0.7257 - val_loss: 2.7900 - val_accuracy: 0.8125\n",
            "Epoch 41/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7870 - accuracy: 0.7257 - val_loss: 2.7734 - val_accuracy: 0.8125\n",
            "Epoch 42/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7706 - accuracy: 0.7257 - val_loss: 2.7571 - val_accuracy: 0.8125\n",
            "Epoch 43/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7538 - accuracy: 0.7257 - val_loss: 2.7399 - val_accuracy: 0.8125\n",
            "Epoch 44/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.7366 - accuracy: 0.7257 - val_loss: 2.7224 - val_accuracy: 0.8125\n",
            "Epoch 45/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.7194 - accuracy: 0.7257 - val_loss: 2.7048 - val_accuracy: 0.8125\n",
            "Epoch 46/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7014 - accuracy: 0.7257 - val_loss: 2.6869 - val_accuracy: 0.8125\n",
            "Epoch 47/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6829 - accuracy: 0.7257 - val_loss: 2.6676 - val_accuracy: 0.8125\n",
            "Epoch 48/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6639 - accuracy: 0.7257 - val_loss: 2.6483 - val_accuracy: 0.8125\n",
            "Epoch 49/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6450 - accuracy: 0.7257 - val_loss: 2.6295 - val_accuracy: 0.8125\n",
            "Epoch 50/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6262 - accuracy: 0.7257 - val_loss: 2.6101 - val_accuracy: 0.8125\n",
            "Epoch 51/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6068 - accuracy: 0.7500 - val_loss: 2.5901 - val_accuracy: 0.8750\n",
            "Epoch 52/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5870 - accuracy: 0.7674 - val_loss: 2.5702 - val_accuracy: 0.8750\n",
            "Epoch 53/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5672 - accuracy: 0.7674 - val_loss: 2.5502 - val_accuracy: 0.8750\n",
            "Epoch 54/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.5471 - accuracy: 0.7569 - val_loss: 2.5296 - val_accuracy: 0.8750\n",
            "Epoch 55/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5272 - accuracy: 0.7535 - val_loss: 2.5091 - val_accuracy: 0.8750\n",
            "Epoch 56/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5067 - accuracy: 0.7361 - val_loss: 2.4880 - val_accuracy: 0.8125\n",
            "Epoch 57/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4852 - accuracy: 0.7361 - val_loss: 2.4659 - val_accuracy: 0.8125\n",
            "Epoch 58/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4637 - accuracy: 0.7361 - val_loss: 2.4445 - val_accuracy: 0.8125\n",
            "Epoch 59/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4422 - accuracy: 0.7361 - val_loss: 2.4224 - val_accuracy: 0.8125\n",
            "Epoch 60/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4206 - accuracy: 0.7500 - val_loss: 2.4001 - val_accuracy: 0.8125\n",
            "Epoch 61/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3989 - accuracy: 0.7361 - val_loss: 2.3788 - val_accuracy: 0.8125\n",
            "Epoch 62/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3775 - accuracy: 0.7431 - val_loss: 2.3563 - val_accuracy: 0.8750\n",
            "Epoch 63/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3555 - accuracy: 0.7674 - val_loss: 2.3338 - val_accuracy: 0.9062\n",
            "Epoch 64/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3335 - accuracy: 0.7917 - val_loss: 2.3119 - val_accuracy: 0.9062\n",
            "Epoch 65/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.3107 - accuracy: 0.7951 - val_loss: 2.2883 - val_accuracy: 0.9062\n",
            "Epoch 66/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2882 - accuracy: 0.7951 - val_loss: 2.2656 - val_accuracy: 0.9062\n",
            "Epoch 67/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2654 - accuracy: 0.7951 - val_loss: 2.2426 - val_accuracy: 0.9062\n",
            "Epoch 68/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2425 - accuracy: 0.7951 - val_loss: 2.2190 - val_accuracy: 0.9062\n",
            "Epoch 69/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2189 - accuracy: 0.7951 - val_loss: 2.1948 - val_accuracy: 0.9062\n",
            "Epoch 70/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1951 - accuracy: 0.7951 - val_loss: 2.1702 - val_accuracy: 0.9062\n",
            "Epoch 71/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1710 - accuracy: 0.7951 - val_loss: 2.1457 - val_accuracy: 0.9062\n",
            "Epoch 72/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1474 - accuracy: 0.7951 - val_loss: 2.1220 - val_accuracy: 0.9062\n",
            "Epoch 73/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1234 - accuracy: 0.7951 - val_loss: 2.0974 - val_accuracy: 0.9062\n",
            "Epoch 74/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0984 - accuracy: 0.8090 - val_loss: 2.0711 - val_accuracy: 0.9062\n",
            "Epoch 75/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.0738 - accuracy: 0.8403 - val_loss: 2.0465 - val_accuracy: 0.9062\n",
            "Epoch 76/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0496 - accuracy: 0.8403 - val_loss: 2.0219 - val_accuracy: 0.9062\n",
            "Epoch 77/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0250 - accuracy: 0.8403 - val_loss: 1.9968 - val_accuracy: 0.9062\n",
            "Epoch 78/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0003 - accuracy: 0.8403 - val_loss: 1.9721 - val_accuracy: 0.9062\n",
            "Epoch 79/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9757 - accuracy: 0.8403 - val_loss: 1.9475 - val_accuracy: 0.9375\n",
            "Epoch 80/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9508 - accuracy: 0.8472 - val_loss: 1.9223 - val_accuracy: 0.9375\n",
            "Epoch 81/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9263 - accuracy: 0.8715 - val_loss: 1.8980 - val_accuracy: 0.9375\n",
            "Epoch 82/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9015 - accuracy: 0.8715 - val_loss: 1.8730 - val_accuracy: 0.9375\n",
            "Epoch 83/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8771 - accuracy: 0.8715 - val_loss: 1.8486 - val_accuracy: 0.9375\n",
            "Epoch 84/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8525 - accuracy: 0.8715 - val_loss: 1.8232 - val_accuracy: 0.9375\n",
            "Epoch 85/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.8280 - accuracy: 0.8715 - val_loss: 1.7985 - val_accuracy: 0.9375\n",
            "Epoch 86/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8032 - accuracy: 0.8715 - val_loss: 1.7734 - val_accuracy: 0.9375\n",
            "Epoch 87/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7780 - accuracy: 0.8715 - val_loss: 1.7478 - val_accuracy: 0.9375\n",
            "Epoch 88/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7531 - accuracy: 0.8715 - val_loss: 1.7226 - val_accuracy: 0.9375\n",
            "Epoch 89/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7282 - accuracy: 0.8715 - val_loss: 1.6975 - val_accuracy: 0.9375\n",
            "Epoch 90/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7030 - accuracy: 0.8715 - val_loss: 1.6713 - val_accuracy: 0.9375\n",
            "Epoch 91/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6775 - accuracy: 0.8715 - val_loss: 1.6455 - val_accuracy: 0.9375\n",
            "Epoch 92/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6525 - accuracy: 0.8715 - val_loss: 1.6204 - val_accuracy: 0.9375\n",
            "Epoch 93/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6275 - accuracy: 0.8715 - val_loss: 1.5948 - val_accuracy: 0.9375\n",
            "Epoch 94/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6026 - accuracy: 0.8715 - val_loss: 1.5696 - val_accuracy: 0.9375\n",
            "Epoch 95/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.5779 - accuracy: 0.8715 - val_loss: 1.5441 - val_accuracy: 0.9375\n",
            "Epoch 96/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5533 - accuracy: 0.8715 - val_loss: 1.5189 - val_accuracy: 0.9375\n",
            "Epoch 97/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5283 - accuracy: 0.8715 - val_loss: 1.4929 - val_accuracy: 0.9375\n",
            "Epoch 98/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5038 - accuracy: 0.8715 - val_loss: 1.4683 - val_accuracy: 0.9375\n",
            "Epoch 99/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4792 - accuracy: 0.8924 - val_loss: 1.4435 - val_accuracy: 0.9375\n",
            "Epoch 100/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4547 - accuracy: 0.9132 - val_loss: 1.4186 - val_accuracy: 0.9375\n",
            "Epoch 101/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4299 - accuracy: 0.9271 - val_loss: 1.3936 - val_accuracy: 0.9375\n",
            "Epoch 102/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4056 - accuracy: 0.9271 - val_loss: 1.3695 - val_accuracy: 0.9375\n",
            "Epoch 103/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3816 - accuracy: 0.9271 - val_loss: 1.3452 - val_accuracy: 0.9375\n",
            "Epoch 104/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3576 - accuracy: 0.9271 - val_loss: 1.3206 - val_accuracy: 0.9375\n",
            "Epoch 105/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.3336 - accuracy: 0.9271 - val_loss: 1.2957 - val_accuracy: 0.9375\n",
            "Epoch 106/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3091 - accuracy: 0.9271 - val_loss: 1.2705 - val_accuracy: 0.9375\n",
            "Epoch 107/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2844 - accuracy: 0.9271 - val_loss: 1.2459 - val_accuracy: 0.9375\n",
            "Epoch 108/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2597 - accuracy: 0.9271 - val_loss: 1.2209 - val_accuracy: 0.9375\n",
            "Epoch 109/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2351 - accuracy: 0.9271 - val_loss: 1.1959 - val_accuracy: 0.9375\n",
            "Epoch 110/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2112 - accuracy: 0.9271 - val_loss: 1.1716 - val_accuracy: 0.9375\n",
            "Epoch 111/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1876 - accuracy: 0.9271 - val_loss: 1.1479 - val_accuracy: 0.9375\n",
            "Epoch 112/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1638 - accuracy: 0.9271 - val_loss: 1.1243 - val_accuracy: 0.9375\n",
            "Epoch 113/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1401 - accuracy: 0.9410 - val_loss: 1.0996 - val_accuracy: 0.9688\n",
            "Epoch 114/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1162 - accuracy: 0.9583 - val_loss: 1.0752 - val_accuracy: 0.9688\n",
            "Epoch 115/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0931 - accuracy: 0.9583 - val_loss: 1.0511 - val_accuracy: 0.9688\n",
            "Epoch 116/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0697 - accuracy: 0.9583 - val_loss: 1.0277 - val_accuracy: 0.9688\n",
            "Epoch 117/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0467 - accuracy: 0.9583 - val_loss: 1.0043 - val_accuracy: 0.9688\n",
            "Epoch 118/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0238 - accuracy: 0.9583 - val_loss: 0.9808 - val_accuracy: 0.9688\n",
            "Epoch 119/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0011 - accuracy: 0.9583 - val_loss: 0.9577 - val_accuracy: 0.9688\n",
            "Epoch 120/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9786 - accuracy: 0.9688 - val_loss: 0.9353 - val_accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9566 - accuracy: 0.9826 - val_loss: 0.9133 - val_accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9346 - accuracy: 0.9826 - val_loss: 0.8907 - val_accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9129 - accuracy: 0.9826 - val_loss: 0.8685 - val_accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8914 - accuracy: 0.9826 - val_loss: 0.8464 - val_accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8700 - accuracy: 0.9826 - val_loss: 0.8245 - val_accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8487 - accuracy: 0.9826 - val_loss: 0.8021 - val_accuracy: 1.0000\n",
            "Epoch 127/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8276 - accuracy: 0.9826 - val_loss: 0.7813 - val_accuracy: 1.0000\n",
            "Epoch 128/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8067 - accuracy: 0.9826 - val_loss: 0.7599 - val_accuracy: 1.0000\n",
            "Epoch 129/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7864 - accuracy: 0.9826 - val_loss: 0.7396 - val_accuracy: 1.0000\n",
            "Epoch 130/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7665 - accuracy: 0.9931 - val_loss: 0.7191 - val_accuracy: 1.0000\n",
            "Epoch 131/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 1.0000\n",
            "Epoch 132/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7267 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 1.0000\n",
            "Epoch 133/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 1.0000 - val_loss: 0.6607 - val_accuracy: 1.0000\n",
            "Epoch 134/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 1.0000 - val_loss: 0.6420 - val_accuracy: 1.0000\n",
            "Epoch 135/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 1.0000 - val_loss: 0.6050 - val_accuracy: 1.0000\n",
            "Epoch 137/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 1.0000 - val_loss: 0.5864 - val_accuracy: 1.0000\n",
            "Epoch 138/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 1.0000\n",
            "Epoch 139/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 1.0000 - val_loss: 0.5504 - val_accuracy: 1.0000\n",
            "Epoch 140/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 1.0000 - val_loss: 0.5328 - val_accuracy: 1.0000\n",
            "Epoch 141/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 1.0000\n",
            "Epoch 142/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 1.0000\n",
            "Epoch 143/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 1.0000\n",
            "Epoch 150/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 1.0000\n",
            "Epoch 153/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 1.0000\n",
            "Epoch 162/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 1.0000\n",
            "Epoch 163/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2071 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1901 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 1.0000\n",
            "Epoch 180/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 1.0000\n",
            "Epoch 183/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
            "Epoch 195/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
            "Epoch 196/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
            "Epoch 200/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.6074e-04 - val_accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.9625e-04 - val_accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.4187e-04 - val_accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.7844e-04 - val_accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.9352e-04 - accuracy: 1.0000 - val_loss: 7.2353e-04 - val_accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 9.2692e-04 - accuracy: 1.0000 - val_loss: 6.7414e-04 - val_accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.6388e-04 - accuracy: 1.0000 - val_loss: 6.2562e-04 - val_accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.0577e-04 - accuracy: 1.0000 - val_loss: 5.8273e-04 - val_accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.5147e-04 - accuracy: 1.0000 - val_loss: 5.4225e-04 - val_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.9935e-04 - accuracy: 1.0000 - val_loss: 5.0522e-04 - val_accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.5371e-04 - accuracy: 1.0000 - val_loss: 4.7043e-04 - val_accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.0908e-04 - accuracy: 1.0000 - val_loss: 4.3855e-04 - val_accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.6755e-04 - accuracy: 1.0000 - val_loss: 4.0801e-04 - val_accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.2770e-04 - accuracy: 1.0000 - val_loss: 3.8006e-04 - val_accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.9211e-04 - accuracy: 1.0000 - val_loss: 3.5336e-04 - val_accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 4.5806e-04 - accuracy: 1.0000 - val_loss: 3.2898e-04 - val_accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.2591e-04 - accuracy: 1.0000 - val_loss: 3.0503e-04 - val_accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.9609e-04 - accuracy: 1.0000 - val_loss: 2.8207e-04 - val_accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.6769e-04 - accuracy: 1.0000 - val_loss: 2.6010e-04 - val_accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.4234e-04 - accuracy: 1.0000 - val_loss: 2.4156e-04 - val_accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1772e-04 - accuracy: 1.0000 - val_loss: 2.2467e-04 - val_accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9496e-04 - accuracy: 1.0000 - val_loss: 2.0825e-04 - val_accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7340e-04 - accuracy: 1.0000 - val_loss: 1.9316e-04 - val_accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.5330e-04 - accuracy: 1.0000 - val_loss: 1.7814e-04 - val_accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3493e-04 - accuracy: 1.0000 - val_loss: 1.6501e-04 - val_accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.1781e-04 - accuracy: 1.0000 - val_loss: 1.5281e-04 - val_accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0193e-04 - accuracy: 1.0000 - val_loss: 1.4144e-04 - val_accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8763e-04 - accuracy: 1.0000 - val_loss: 1.3247e-04 - val_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7362e-04 - accuracy: 1.0000 - val_loss: 1.2227e-04 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6044e-04 - accuracy: 1.0000 - val_loss: 1.1311e-04 - val_accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4783e-04 - accuracy: 1.0000 - val_loss: 1.0393e-04 - val_accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3635e-04 - accuracy: 1.0000 - val_loss: 9.6170e-05 - val_accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2593e-04 - accuracy: 1.0000 - val_loss: 8.8848e-05 - val_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1630e-04 - accuracy: 1.0000 - val_loss: 8.1499e-05 - val_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0742e-04 - accuracy: 1.0000 - val_loss: 7.5506e-05 - val_accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 9.9160e-05 - accuracy: 1.0000 - val_loss: 6.9420e-05 - val_accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 9.1403e-05 - accuracy: 1.0000 - val_loss: 6.3944e-05 - val_accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.4126e-05 - accuracy: 1.0000 - val_loss: 5.8648e-05 - val_accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.7319e-05 - accuracy: 1.0000 - val_loss: 5.3891e-05 - val_accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.1323e-05 - accuracy: 1.0000 - val_loss: 4.9734e-05 - val_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.5655e-05 - accuracy: 1.0000 - val_loss: 4.5566e-05 - val_accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.0466e-05 - accuracy: 1.0000 - val_loss: 4.2161e-05 - val_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 5.5630e-05 - accuracy: 1.0000 - val_loss: 3.8641e-05 - val_accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.1213e-05 - accuracy: 1.0000 - val_loss: 3.5557e-05 - val_accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 4.7164e-05 - accuracy: 1.0000 - val_loss: 3.2875e-05 - val_accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.3391e-05 - accuracy: 1.0000 - val_loss: 3.0193e-05 - val_accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 4.0002e-05 - accuracy: 1.0000 - val_loss: 2.7980e-05 - val_accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.6756e-05 - accuracy: 1.0000 - val_loss: 2.5719e-05 - val_accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.3755e-05 - accuracy: 1.0000 - val_loss: 2.3510e-05 - val_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1005e-05 - accuracy: 1.0000 - val_loss: 2.1554e-05 - val_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8455e-05 - accuracy: 1.0000 - val_loss: 1.9952e-05 - val_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.6090e-05 - accuracy: 1.0000 - val_loss: 1.8403e-05 - val_accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3994e-05 - accuracy: 1.0000 - val_loss: 1.6816e-05 - val_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.1985e-05 - accuracy: 1.0000 - val_loss: 1.5501e-05 - val_accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0138e-05 - accuracy: 1.0000 - val_loss: 1.4167e-05 - val_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8528e-05 - accuracy: 1.0000 - val_loss: 1.3057e-05 - val_accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7050e-05 - accuracy: 1.0000 - val_loss: 1.1988e-05 - val_accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5663e-05 - accuracy: 1.0000 - val_loss: 1.1012e-05 - val_accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4357e-05 - accuracy: 1.0000 - val_loss: 1.0051e-05 - val_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3193e-05 - accuracy: 1.0000 - val_loss: 9.2573e-06 - val_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2128e-05 - accuracy: 1.0000 - val_loss: 8.5644e-06 - val_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1146e-05 - accuracy: 1.0000 - val_loss: 7.8491e-06 - val_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0236e-05 - accuracy: 1.0000 - val_loss: 7.1898e-06 - val_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.3934e-06 - accuracy: 1.0000 - val_loss: 6.6049e-06 - val_accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.6335e-06 - accuracy: 1.0000 - val_loss: 6.0796e-06 - val_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.9389e-06 - accuracy: 1.0000 - val_loss: 5.6289e-06 - val_accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.3060e-06 - accuracy: 1.0000 - val_loss: 5.1968e-06 - val_accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.7017e-06 - accuracy: 1.0000 - val_loss: 4.7721e-06 - val_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.1616e-06 - accuracy: 1.0000 - val_loss: 4.3996e-06 - val_accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.6736e-06 - accuracy: 1.0000 - val_loss: 4.0382e-06 - val_accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.2158e-06 - accuracy: 1.0000 - val_loss: 3.7327e-06 - val_accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.8159e-06 - accuracy: 1.0000 - val_loss: 3.4422e-06 - val_accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.4401e-06 - accuracy: 1.0000 - val_loss: 3.1963e-06 - val_accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.0854e-06 - accuracy: 1.0000 - val_loss: 2.9430e-06 - val_accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.7613e-06 - accuracy: 1.0000 - val_loss: 2.7493e-06 - val_accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.4984e-06 - accuracy: 1.0000 - val_loss: 2.5220e-06 - val_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2021e-06 - accuracy: 1.0000 - val_loss: 2.3320e-06 - val_accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9740e-06 - accuracy: 1.0000 - val_loss: 2.1569e-06 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7687e-06 - accuracy: 1.0000 - val_loss: 2.0005e-06 - val_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5522e-06 - accuracy: 1.0000 - val_loss: 1.8738e-06 - val_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3676e-06 - accuracy: 1.0000 - val_loss: 1.7509e-06 - val_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.1942e-06 - accuracy: 1.0000 - val_loss: 1.6466e-06 - val_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0336e-06 - accuracy: 1.0000 - val_loss: 1.4901e-06 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8987e-06 - accuracy: 1.0000 - val_loss: 1.4305e-06 - val_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7745e-06 - accuracy: 1.0000 - val_loss: 1.3299e-06 - val_accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6420e-06 - accuracy: 1.0000 - val_loss: 1.2554e-06 - val_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5406e-06 - accuracy: 1.0000 - val_loss: 1.1586e-06 - val_accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4384e-06 - accuracy: 1.0000 - val_loss: 1.1027e-06 - val_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3568e-06 - accuracy: 1.0000 - val_loss: 1.0245e-06 - val_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2600e-06 - accuracy: 1.0000 - val_loss: 9.6112e-07 - val_accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1793e-06 - accuracy: 1.0000 - val_loss: 9.1642e-07 - val_accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0985e-06 - accuracy: 1.0000 - val_loss: 8.5309e-07 - val_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0439e-06 - accuracy: 1.0000 - val_loss: 8.0466e-07 - val_accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.8679e-07 - accuracy: 1.0000 - val_loss: 7.8604e-07 - val_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.2594e-07 - accuracy: 1.0000 - val_loss: 7.1898e-07 - val_accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.6551e-07 - accuracy: 1.0000 - val_loss: 6.7055e-07 - val_accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.0963e-07 - accuracy: 1.0000 - val_loss: 6.2957e-07 - val_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.7031e-07 - accuracy: 1.0000 - val_loss: 6.1467e-07 - val_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.3057e-07 - accuracy: 1.0000 - val_loss: 5.9232e-07 - val_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.9415e-07 - accuracy: 1.0000 - val_loss: 5.6252e-07 - val_accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.5979e-07 - accuracy: 1.0000 - val_loss: 5.4017e-07 - val_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.1384e-07 - accuracy: 1.0000 - val_loss: 4.9174e-07 - val_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.8404e-07 - accuracy: 1.0000 - val_loss: 4.8429e-07 - val_accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.6004e-07 - accuracy: 1.0000 - val_loss: 4.6566e-07 - val_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.3851e-07 - accuracy: 1.0000 - val_loss: 4.3586e-07 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.0498e-07 - accuracy: 1.0000 - val_loss: 4.0606e-07 - val_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.7518e-07 - accuracy: 1.0000 - val_loss: 3.9116e-07 - val_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.5573e-07 - accuracy: 1.0000 - val_loss: 3.7625e-07 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.3710e-07 - accuracy: 1.0000 - val_loss: 3.4645e-07 - val_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.2592e-07 - accuracy: 1.0000 - val_loss: 3.3900e-07 - val_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.0730e-07 - accuracy: 1.0000 - val_loss: 3.3900e-07 - val_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.9488e-07 - accuracy: 1.0000 - val_loss: 3.2410e-07 - val_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.7377e-07 - accuracy: 1.0000 - val_loss: 3.0920e-07 - val_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.5639e-07 - accuracy: 1.0000 - val_loss: 2.9430e-07 - val_accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.3900e-07 - accuracy: 1.0000 - val_loss: 2.8685e-07 - val_accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1996e-07 - accuracy: 1.0000 - val_loss: 2.6450e-07 - val_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0920e-07 - accuracy: 1.0000 - val_loss: 2.6450e-07 - val_accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9513e-07 - accuracy: 1.0000 - val_loss: 2.5332e-07 - val_accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7857e-07 - accuracy: 1.0000 - val_loss: 2.3097e-07 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7070e-07 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6657e-07 - accuracy: 1.0000 - val_loss: 2.3097e-07 - val_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5166e-07 - accuracy: 1.0000 - val_loss: 2.2724e-07 - val_accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3966e-07 - accuracy: 1.0000 - val_loss: 2.0862e-07 - val_accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2310e-07 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.1234e-07 - accuracy: 1.0000 - val_loss: 1.8626e-07 - val_accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0199e-07 - accuracy: 1.0000 - val_loss: 1.6391e-07 - val_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8751e-07 - accuracy: 1.0000 - val_loss: 1.6391e-07 - val_accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8461e-07 - accuracy: 1.0000 - val_loss: 1.6764e-07 - val_accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7840e-07 - accuracy: 1.0000 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7509e-07 - accuracy: 1.0000 - val_loss: 1.6019e-07 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6847e-07 - accuracy: 1.0000 - val_loss: 1.4156e-07 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6267e-07 - accuracy: 1.0000 - val_loss: 1.4156e-07 - val_accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.5563e-07 - accuracy: 1.0000 - val_loss: 1.3784e-07 - val_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5067e-07 - accuracy: 1.0000 - val_loss: 1.4529e-07 - val_accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5315e-07 - accuracy: 1.0000 - val_loss: 1.4529e-07 - val_accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4818e-07 - accuracy: 1.0000 - val_loss: 1.3039e-07 - val_accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4694e-07 - accuracy: 1.0000 - val_loss: 1.3039e-07 - val_accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4322e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4073e-07 - accuracy: 1.0000 - val_loss: 1.3784e-07 - val_accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4322e-07 - accuracy: 1.0000 - val_loss: 1.1548e-07 - val_accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3494e-07 - accuracy: 1.0000 - val_loss: 1.0803e-07 - val_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3452e-07 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2500e-07 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2086e-07 - accuracy: 1.0000 - val_loss: 1.0803e-07 - val_accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2211e-07 - accuracy: 1.0000 - val_loss: 1.0058e-07 - val_accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1631e-07 - accuracy: 1.0000 - val_loss: 1.0058e-07 - val_accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1838e-07 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1880e-07 - accuracy: 1.0000 - val_loss: 8.5682e-08 - val_accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1176e-07 - accuracy: 1.0000 - val_loss: 1.0803e-07 - val_accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1548e-07 - accuracy: 1.0000 - val_loss: 9.3132e-08 - val_accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1300e-07 - accuracy: 1.0000 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0514e-07 - accuracy: 1.0000 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0721e-07 - accuracy: 1.0000 - val_loss: 8.5682e-08 - val_accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0141e-07 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0348e-07 - accuracy: 1.0000 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.8927e-08 - accuracy: 1.0000 - val_loss: 9.6858e-08 - val_accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.6444e-08 - accuracy: 1.0000 - val_loss: 7.0781e-08 - val_accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.3612e-08 - accuracy: 1.0000 - val_loss: 8.5682e-08 - val_accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.6989e-08 - accuracy: 1.0000 - val_loss: 7.8231e-08 - val_accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.2850e-08 - accuracy: 1.0000 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.1608e-08 - accuracy: 1.0000 - val_loss: 5.5879e-08 - val_accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 7.0367e-08 - accuracy: 1.0000 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.2502e-08 - accuracy: 1.0000 - val_loss: 5.5879e-08 - val_accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.9605e-08 - accuracy: 1.0000 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 5.9605e-08 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.6707e-08 - accuracy: 1.0000 - val_loss: 4.8429e-08 - val_accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.4638e-08 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.0498e-08 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.7121e-08 - accuracy: 1.0000 - val_loss: 4.8429e-08 - val_accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.1740e-08 - accuracy: 1.0000 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.1326e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.9736e-08 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.5531e-08 - accuracy: 1.0000 - val_loss: 4.8429e-08 - val_accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.1392e-08 - accuracy: 1.0000 - val_loss: 4.8429e-08 - val_accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.5597e-08 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.8909e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.6425e-08 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.5183e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.6839e-08 - accuracy: 1.0000 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1044e-08 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0216e-08 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2286e-08 - accuracy: 1.0000 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1872e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1872e-08 - accuracy: 1.0000 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8561e-08 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.5597e-08 - accuracy: 1.0000 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9388e-08 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1872e-08 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2700e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0630e-08 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6077e-08 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6905e-08 - accuracy: 1.0000 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6905e-08 - accuracy: 1.0000 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "22/29 [=====================>........] - ETA: 0s - loss: 2.6551e-08 - accuracy: 1.0000Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4835e-08 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
            "Epoch 00455: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3ff978dcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KK0yXhBzEdZ"
      },
      "source": [
        "History = model_ROT13.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kBrNzl2zEde",
        "outputId": "52e66d8b-4ea8-499e-8b6d-9327eb47fdc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(History.history['accuracy'])\n",
        "plt.title('Accuracy VS Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWydA_CUzEdj",
        "outputId": "e8d37b75-4897-4576-973d-e3cc4f79187c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(History.history['loss'])\n",
        "plt.title('Loss VS Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gMf_ztgzEdn"
      },
      "source": [
        "## Testing the Shallow Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXU8nb5jzEdo",
        "outputId": "a40f3e6b-ed91-4cf6-83b9-958f02a5f710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "Loss,Accuracy=model_ROT13.evaluate(X_test,Y_test,verbose=1)\n",
        "print('Accuracy: ',Accuracy)\n",
        "print('Loss: ',Loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 2ms/step - loss: 4.6194e-08 - accuracy: 1.0000\n",
            "Accuracy:  1.0\n",
            "Loss:  4.6193594727128584e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLJgO3UrzEds"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N0vm_7gzEdt"
      },
      "source": [
        "Name='Model 2.3 - ROT13 39'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF91GtcOzEdx"
      },
      "source": [
        "Name=Name + ' - ' + str(datetime.datetime.now()) + '.h5'\n",
        "model_ROT13.save('/content/drive/My Drive/AI Breaks Cryptography/Models/'+Name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KNSnGebzEd6"
      },
      "source": [
        "## Decoding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQMmgmFjzEd7",
        "outputId": "e75897e4-8a80-44c6-ceb5-b05443215200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "Categories=[i for i in CHOICES]\n",
        "Label_Encoding=LabelEncoder().fit_transform(Categories).reshape(-1,1)\n",
        "One_Hot_Encoding=OneHotEncoder().fit_transform(Label_Encoding).toarray()\n",
        "Categories_Dictionary={Categories[i]:One_Hot_Encoding[i] for i in range(len(Categories))}\n",
        "Categories_Dictionary_Reverse={tuple(One_Hot_Encoding[i]):Categories[i] for i in range(len(Categories))}\n",
        "print(Categories_Dictionary)\n",
        "print(Categories_Dictionary_Reverse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'A': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'B': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'C': array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'D': array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'E': array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'F': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'G': array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'H': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'I': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'J': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'K': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'L': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'M': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'N': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'O': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'P': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'Q': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'R': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       1., 0., 0., 0., 0., 0., 0., 0., 0.]), 'S': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 1., 0., 0., 0., 0., 0., 0., 0.]), 'T': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'U': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 1., 0., 0., 0., 0., 0.]), 'V': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'W': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 1., 0., 0., 0.]), 'X': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 1., 0., 0.]), 'Y': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 1., 0.]), 'Z': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 1.])}\n",
            "{(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'A', (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'B', (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'C', (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'D', (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'E', (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'F', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'G', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'H', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'I', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'J', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'K', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'L', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'M', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'N', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'O', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'P', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'Q', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'R', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'S', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'T', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'U', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0): 'V', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0): 'W', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0): 'X', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0): 'Y', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0): 'Z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R49Y2ApAzEd-"
      },
      "source": [
        "def Decode(character,Categories_Dictionary_Reverse=Categories_Dictionary_Reverse):\n",
        "  #print(np.array(Categories_Dictionary[character]).shape)\n",
        "  prediction=model_ROT13.predict(np.array(Categories_Dictionary[character]).reshape(1,26))\n",
        "  prediction=prediction>=prediction.max()\n",
        "  #print(prediction)\n",
        "  temp=[0.0 for i in range(26)]\n",
        "  for i in range(len(prediction[0])):\n",
        "    if prediction[0][i]==True:\n",
        "      temp[i]=1\n",
        "  return Categories_Dictionary_Reverse[tuple(temp)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq0WWamYzEeB",
        "outputId": "dd67a93c-65c8-43ad-d654-75de23b222d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "character='N'\n",
        "print(character)\n",
        "print(Decode(character))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N\n",
            "A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9axZHImGzEeE"
      },
      "source": [
        "## AI Based Decryption of ROT13 Cipher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aLl5S-dzEeE",
        "outputId": "828b8c11-3357-4673-82c7-ea82ec3b2a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "MESSAGE=\"CHRISTEEN T JOSE\"\n",
        "MESSAGE=MESSAGE.upper()\n",
        "print(\"\\t\\tOriginal Message:\\t\\t\\t\\t\",MESSAGE)\n",
        "ENCRYPTED_MESSAGE=ROT13(MESSAGE)\n",
        "print(\"\\n\\n\\t\\tMessage after Encryption using ROT13 Cipher:\\t\",ENCRYPTED_MESSAGE)\n",
        "#print(\"Key used for Encryption: \",KEY)\n",
        "DECRYPTED_MESSAGE=''\n",
        "for i in ENCRYPTED_MESSAGE:\n",
        "  if i==' ':\n",
        "    DECRYPTED_MESSAGE+=i\n",
        "  else:\n",
        "    DECRYPTED_MESSAGE+=Decode(i)\n",
        "print(\"\\n\\n\\t\\tMessage after AI based Decryption:\\t\\t\",DECRYPTED_MESSAGE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tOriginal Message:\t\t\t\t CHRISTEEN T JOSE\n",
            "\n",
            "\n",
            "\t\tMessage after Encryption using ROT13 Cipher:\t PUEVFGRRA G WBFR\n",
            "\n",
            "\n",
            "\t\tMessage after AI based Decryption:\t\t CHRISTEEN T JOSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNYzSGIHOPe5"
      },
      "source": [
        "# Simple Substitution Cipher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3luTy3XPOPe8"
      },
      "source": [
        "## Known-Plaintext Attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrkK8UyWOPe-"
      },
      "source": [
        "### Fixed Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq5pIdwFOPe_"
      },
      "source": [
        "KEY='ProjectReviewISAA'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NatiOjxLOPfG"
      },
      "source": [
        "### Password Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_bIkK_gOPfH"
      },
      "source": [
        "PASSWORD_SIZE=8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5jRCtw3OPfM"
      },
      "source": [
        "### Dataset Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F42JH5ohOPfN"
      },
      "source": [
        "DATASET_SIZE=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKY0CKe7OPfU"
      },
      "source": [
        "### Generation of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9byQ8JKOPfV",
        "outputId": "6e4a3993-291f-461f-bc54-9784b4dfe39d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "CHOICES=CaesarCipher_characterset()\n",
        "CHOICES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ_pJS_iOPfa",
        "outputId": "5cf252a3-2331-43fe-8ea7-c2abb098ff80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for i in range(DATASET_SIZE):\n",
        "  temp=''\n",
        "  for j in range(PASSWORD_SIZE):\n",
        "    temp+=random.choice(CHOICES)\n",
        "  x.append(temp)\n",
        "  y.append(SimpleSubstitutionCipher_encryption(temp,KEY))\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['KICUHOIL', 'HJYBVVIF', 'SMSYVTFW', 'BSTUOHRE', 'FZTEHPQA', 'YGRLMGQE', 'BIQZWHMJ', 'DFFHYXWV', 'MEWJJUYW', 'IEJNIAHR', 'HXPAAQYU', 'UYGLSQEN', 'FCEYEOOZ', 'UCTTIQMJ', 'GILAUMSK', 'LILNTNBJ', 'DUPDIMYR', 'FSWODPSK', 'SFAYGXMS', 'IXBRECEK', 'AABIQLQE', 'YWHWWBOR', 'KVTTHCNX', 'CBREAWEZ', 'OOEBLUAI', 'YEKDRWFS', 'CZYICKSH', 'CKSCPZGV', 'REQXPPVE', 'DOBVVXCF', 'AIEKHMNB', 'NBNYDNLQ', 'FSMVCEMC', 'PKJKVBPB', 'BAMUZNGC', 'KYYJXEZM', 'PHRUHTYM', 'IJYBRHAY', 'MBZPVQOV', 'VOMYMXNC', 'VTCRYYJB', 'FKQHATMT', 'UUJXEIJR', 'OZPUEURT', 'SGBFTPSC', 'OTOMSWLX', 'WNTXMPAC', 'ALAYQGJJ', 'XQSTSJMC', 'IWJTRFEY']\n",
            "['SIONVFIA', 'VWYRQQIC', 'LBLYQMCU', 'RLMNFVKE', 'CZMEVGHP', 'YTKABTHE', 'RIHZUVBW', 'JCCVYXUQ', 'BEUWWNYU', 'IEWDIPVK', 'VXGPPHYN', 'NYTALHED', 'COEYEFFZ', 'NOMMIHBW', 'TIAPNBLS', 'AIADMDRW', 'JNGJIBYK', 'CLUFJGLS', 'LCPYTXBL', 'IXRKEOES', 'PPRIHAHE', 'YUVUURFK', 'SQMMVODX', 'ORKEPUEZ', 'FFERANPI', 'YESJKUCL', 'OZYIOSLV', 'OSLOGZTQ', 'KEHXGGQE', 'JFRQQXOC', 'PIESVBDR', 'DRDYJDAH', 'CLBQOEBO', 'GSWSQRGR', 'RPBNZDTO', 'SYYWXEZB', 'GVKNVMYB', 'IWYRKVPY', 'BRZGQHFQ', 'QFBYBXDO', 'QMOKYYWR', 'CSHVPMBM', 'NNWXEIWK', 'FZGNENKM', 'LTRCMGLO', 'FMFBLUAX', 'UDMXBGPO', 'PAPYHTWW', 'XHLMLWBO', 'IUWMKCEY']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQr1vR0GOPff",
        "outputId": "4c2e3289-b88b-4e7d-f6ee-ef6d0adfbb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "Data=pd.DataFrame({'Plaintext':x,'Ciphertext':y})\n",
        "Data.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plaintext</th>\n",
              "      <th>Ciphertext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KICUHOIL</td>\n",
              "      <td>SIONVFIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HJYBVVIF</td>\n",
              "      <td>VWYRQQIC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SMSYVTFW</td>\n",
              "      <td>LBLYQMCU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BSTUOHRE</td>\n",
              "      <td>RLMNFVKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FZTEHPQA</td>\n",
              "      <td>CZMEVGHP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>YGRLMGQE</td>\n",
              "      <td>YTKABTHE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>BIQZWHMJ</td>\n",
              "      <td>RIHZUVBW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DFFHYXWV</td>\n",
              "      <td>JCCVYXUQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MEWJJUYW</td>\n",
              "      <td>BEUWWNYU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>IEJNIAHR</td>\n",
              "      <td>IEWDIPVK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>HXPAAQYU</td>\n",
              "      <td>VXGPPHYN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>UYGLSQEN</td>\n",
              "      <td>NYTALHED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>FCEYEOOZ</td>\n",
              "      <td>COEYEFFZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>UCTTIQMJ</td>\n",
              "      <td>NOMMIHBW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>GILAUMSK</td>\n",
              "      <td>TIAPNBLS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Plaintext Ciphertext\n",
              "0   KICUHOIL   SIONVFIA\n",
              "1   HJYBVVIF   VWYRQQIC\n",
              "2   SMSYVTFW   LBLYQMCU\n",
              "3   BSTUOHRE   RLMNFVKE\n",
              "4   FZTEHPQA   CZMEVGHP\n",
              "5   YGRLMGQE   YTKABTHE\n",
              "6   BIQZWHMJ   RIHZUVBW\n",
              "7   DFFHYXWV   JCCVYXUQ\n",
              "8   MEWJJUYW   BEUWWNYU\n",
              "9   IEJNIAHR   IEWDIPVK\n",
              "10  HXPAAQYU   VXGPPHYN\n",
              "11  UYGLSQEN   NYTALHED\n",
              "12  FCEYEOOZ   COEYEFFZ\n",
              "13  UCTTIQMJ   NOMMIHBW\n",
              "14  GILAUMSK   TIAPNBLS"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OIWPd9uOPfk"
      },
      "source": [
        "### Since Simple Substitution Cipher is a Stream Cipher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIN1dF9ZOPfk",
        "outputId": "5bdd317e-af8c-4945-ae8c-3a044ef1bb85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "plaintext=[]\n",
        "ciphertext=[]\n",
        "for password in x:\n",
        "  for character in password:\n",
        "    plaintext.append(character)\n",
        "for Encrypted_password in y:\n",
        "  for character in Encrypted_password:\n",
        "    ciphertext.append(character)\n",
        "Data=pd.DataFrame({'Plaintext':plaintext,'Ciphertext':ciphertext})\n",
        "Data.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plaintext</th>\n",
              "      <th>Ciphertext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>K</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>O</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>L</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>H</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>J</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>B</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>V</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>V</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Plaintext Ciphertext\n",
              "0          K          S\n",
              "1          I          I\n",
              "2          C          O\n",
              "3          U          N\n",
              "4          H          V\n",
              "5          O          F\n",
              "6          I          I\n",
              "7          L          A\n",
              "8          H          V\n",
              "9          J          W\n",
              "10         Y          Y\n",
              "11         B          R\n",
              "12         V          Q\n",
              "13         V          Q\n",
              "14         I          I"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9Eg4c1AOPfp"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb8BYudtOPfq"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2320gID1OPfs",
        "outputId": "f435af9b-847a-4ed1-c040-38e3109b9eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "plaintext=LabelEncoder().fit_transform(plaintext).reshape(-1, 1)\n",
        "ciphertext=LabelEncoder().fit_transform(ciphertext).reshape(-1, 1)\n",
        "X=OneHotEncoder().fit_transform(plaintext).toarray()\n",
        "Y=OneHotEncoder().fit_transform(ciphertext).toarray()\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBC4aJdUOPfx"
      },
      "source": [
        "### Splitting the Dataset - Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFa6Hcb5OPfy",
        "outputId": "34380f1d-e83b-4d39-8362-793253eae7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(Y,X,test_size=0.2,random_state=0)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-4VHkxKOPf3"
      },
      "source": [
        "## Training the Shallow Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWXkWt8lOPf4",
        "outputId": "301bb6ae-0e53-4e9b-8939-886525dc2dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "model_SS= models.Sequential()\n",
        "model_SS.add(layers.Dense(26, activation='relu',input_shape=(26,)))\n",
        "model_SS.add(layers.Dense(39, activation='relu'))\n",
        "model_SS.add(layers.Dense(26, activation='softmax'))\n",
        "model_SS.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 26)                702       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 39)                1053      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 26)                1040      \n",
            "=================================================================\n",
            "Total params: 2,795\n",
            "Trainable params: 2,795\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3WtAlVNOPf8"
      },
      "source": [
        "EarlyStopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min',restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK1CEUtqOPgB"
      },
      "source": [
        "model_SS.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgX9QP54OPgF",
        "outputId": "3b827350-1410-4dc7-dd44-99b5059b4cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_SS.fit(x=X_train,y=Y_train,epochs=1000,batch_size=10,validation_split=0.1,callbacks=EarlyStopping)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 3.2327 - accuracy: 0.0278 - val_loss: 3.2469 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2210 - accuracy: 0.0278 - val_loss: 3.2373 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2104 - accuracy: 0.0278 - val_loss: 3.2278 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.2000 - accuracy: 0.0278 - val_loss: 3.2185 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1892 - accuracy: 0.0278 - val_loss: 3.2087 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1784 - accuracy: 0.0556 - val_loss: 3.1989 - val_accuracy: 0.0312\n",
            "Epoch 7/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1678 - accuracy: 0.0868 - val_loss: 3.1894 - val_accuracy: 0.0625\n",
            "Epoch 8/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1574 - accuracy: 0.1146 - val_loss: 3.1801 - val_accuracy: 0.0625\n",
            "Epoch 9/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1472 - accuracy: 0.1424 - val_loss: 3.1707 - val_accuracy: 0.0625\n",
            "Epoch 10/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1369 - accuracy: 0.1806 - val_loss: 3.1609 - val_accuracy: 0.1250\n",
            "Epoch 11/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1263 - accuracy: 0.2083 - val_loss: 3.1510 - val_accuracy: 0.1250\n",
            "Epoch 12/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1154 - accuracy: 0.2083 - val_loss: 3.1413 - val_accuracy: 0.1250\n",
            "Epoch 13/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1045 - accuracy: 0.2222 - val_loss: 3.1314 - val_accuracy: 0.1250\n",
            "Epoch 14/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0938 - accuracy: 0.2500 - val_loss: 3.1216 - val_accuracy: 0.1250\n",
            "Epoch 15/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0827 - accuracy: 0.2500 - val_loss: 3.1113 - val_accuracy: 0.1250\n",
            "Epoch 16/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0715 - accuracy: 0.2674 - val_loss: 3.1011 - val_accuracy: 0.1875\n",
            "Epoch 17/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0600 - accuracy: 0.3056 - val_loss: 3.0904 - val_accuracy: 0.2188\n",
            "Epoch 18/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0483 - accuracy: 0.3403 - val_loss: 3.0793 - val_accuracy: 0.2188\n",
            "Epoch 19/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0366 - accuracy: 0.3438 - val_loss: 3.0685 - val_accuracy: 0.2188\n",
            "Epoch 20/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0243 - accuracy: 0.3438 - val_loss: 3.0571 - val_accuracy: 0.2188\n",
            "Epoch 21/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.0116 - accuracy: 0.3542 - val_loss: 3.0455 - val_accuracy: 0.2500\n",
            "Epoch 22/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9990 - accuracy: 0.3889 - val_loss: 3.0342 - val_accuracy: 0.2500\n",
            "Epoch 23/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9863 - accuracy: 0.3924 - val_loss: 3.0219 - val_accuracy: 0.3125\n",
            "Epoch 24/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9731 - accuracy: 0.4097 - val_loss: 3.0099 - val_accuracy: 0.3125\n",
            "Epoch 25/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9598 - accuracy: 0.4375 - val_loss: 2.9972 - val_accuracy: 0.3125\n",
            "Epoch 26/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9463 - accuracy: 0.4375 - val_loss: 2.9842 - val_accuracy: 0.3125\n",
            "Epoch 27/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9324 - accuracy: 0.4653 - val_loss: 2.9711 - val_accuracy: 0.3750\n",
            "Epoch 28/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9182 - accuracy: 0.4896 - val_loss: 2.9577 - val_accuracy: 0.3750\n",
            "Epoch 29/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9037 - accuracy: 0.4896 - val_loss: 2.9443 - val_accuracy: 0.3750\n",
            "Epoch 30/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8890 - accuracy: 0.4896 - val_loss: 2.9305 - val_accuracy: 0.3750\n",
            "Epoch 31/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8740 - accuracy: 0.4896 - val_loss: 2.9163 - val_accuracy: 0.3750\n",
            "Epoch 32/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8586 - accuracy: 0.4896 - val_loss: 2.9021 - val_accuracy: 0.3750\n",
            "Epoch 33/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8429 - accuracy: 0.4896 - val_loss: 2.8871 - val_accuracy: 0.3750\n",
            "Epoch 34/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8267 - accuracy: 0.4896 - val_loss: 2.8722 - val_accuracy: 0.4375\n",
            "Epoch 35/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8103 - accuracy: 0.5382 - val_loss: 2.8568 - val_accuracy: 0.4375\n",
            "Epoch 36/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7936 - accuracy: 0.5451 - val_loss: 2.8411 - val_accuracy: 0.4375\n",
            "Epoch 37/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7767 - accuracy: 0.5451 - val_loss: 2.8252 - val_accuracy: 0.4375\n",
            "Epoch 38/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7593 - accuracy: 0.5451 - val_loss: 2.8088 - val_accuracy: 0.4375\n",
            "Epoch 39/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7419 - accuracy: 0.5451 - val_loss: 2.7926 - val_accuracy: 0.4375\n",
            "Epoch 40/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7244 - accuracy: 0.5521 - val_loss: 2.7760 - val_accuracy: 0.5312\n",
            "Epoch 41/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7071 - accuracy: 0.5938 - val_loss: 2.7592 - val_accuracy: 0.5312\n",
            "Epoch 42/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6895 - accuracy: 0.6076 - val_loss: 2.7427 - val_accuracy: 0.5312\n",
            "Epoch 43/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6715 - accuracy: 0.6111 - val_loss: 2.7256 - val_accuracy: 0.5312\n",
            "Epoch 44/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.6531 - accuracy: 0.6181 - val_loss: 2.7084 - val_accuracy: 0.5312\n",
            "Epoch 45/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6345 - accuracy: 0.6424 - val_loss: 2.6906 - val_accuracy: 0.5312\n",
            "Epoch 46/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6157 - accuracy: 0.6493 - val_loss: 2.6728 - val_accuracy: 0.5312\n",
            "Epoch 47/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5969 - accuracy: 0.6493 - val_loss: 2.6550 - val_accuracy: 0.5312\n",
            "Epoch 48/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5781 - accuracy: 0.6493 - val_loss: 2.6371 - val_accuracy: 0.5312\n",
            "Epoch 49/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.5588 - accuracy: 0.6493 - val_loss: 2.6191 - val_accuracy: 0.5312\n",
            "Epoch 50/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5391 - accuracy: 0.6493 - val_loss: 2.6008 - val_accuracy: 0.5312\n",
            "Epoch 51/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5187 - accuracy: 0.6493 - val_loss: 2.5812 - val_accuracy: 0.5312\n",
            "Epoch 52/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4983 - accuracy: 0.6493 - val_loss: 2.5621 - val_accuracy: 0.5312\n",
            "Epoch 53/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4779 - accuracy: 0.6597 - val_loss: 2.5430 - val_accuracy: 0.5312\n",
            "Epoch 54/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4574 - accuracy: 0.6910 - val_loss: 2.5235 - val_accuracy: 0.5312\n",
            "Epoch 55/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4362 - accuracy: 0.6910 - val_loss: 2.5031 - val_accuracy: 0.5312\n",
            "Epoch 56/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4145 - accuracy: 0.6910 - val_loss: 2.4829 - val_accuracy: 0.5312\n",
            "Epoch 57/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3928 - accuracy: 0.7188 - val_loss: 2.4627 - val_accuracy: 0.5938\n",
            "Epoch 58/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3714 - accuracy: 0.7257 - val_loss: 2.4424 - val_accuracy: 0.5938\n",
            "Epoch 59/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3496 - accuracy: 0.7257 - val_loss: 2.4225 - val_accuracy: 0.5938\n",
            "Epoch 60/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3273 - accuracy: 0.7257 - val_loss: 2.4018 - val_accuracy: 0.5938\n",
            "Epoch 61/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3051 - accuracy: 0.7257 - val_loss: 2.3815 - val_accuracy: 0.5938\n",
            "Epoch 62/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2831 - accuracy: 0.7396 - val_loss: 2.3605 - val_accuracy: 0.6250\n",
            "Epoch 63/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2599 - accuracy: 0.7778 - val_loss: 2.3382 - val_accuracy: 0.7500\n",
            "Epoch 64/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2363 - accuracy: 0.8056 - val_loss: 2.3170 - val_accuracy: 0.7500\n",
            "Epoch 65/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2129 - accuracy: 0.8056 - val_loss: 2.2952 - val_accuracy: 0.7500\n",
            "Epoch 66/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1902 - accuracy: 0.8056 - val_loss: 2.2743 - val_accuracy: 0.7500\n",
            "Epoch 67/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1670 - accuracy: 0.8056 - val_loss: 2.2521 - val_accuracy: 0.7500\n",
            "Epoch 68/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1432 - accuracy: 0.8056 - val_loss: 2.2298 - val_accuracy: 0.7500\n",
            "Epoch 69/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1198 - accuracy: 0.8056 - val_loss: 2.2078 - val_accuracy: 0.7500\n",
            "Epoch 70/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0958 - accuracy: 0.8056 - val_loss: 2.1856 - val_accuracy: 0.7500\n",
            "Epoch 71/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0717 - accuracy: 0.8056 - val_loss: 2.1631 - val_accuracy: 0.7500\n",
            "Epoch 72/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0474 - accuracy: 0.8056 - val_loss: 2.1402 - val_accuracy: 0.7500\n",
            "Epoch 73/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.0229 - accuracy: 0.8160 - val_loss: 2.1170 - val_accuracy: 0.7500\n",
            "Epoch 74/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9985 - accuracy: 0.8264 - val_loss: 2.0933 - val_accuracy: 0.7500\n",
            "Epoch 75/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9738 - accuracy: 0.8299 - val_loss: 2.0699 - val_accuracy: 0.7500\n",
            "Epoch 76/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9493 - accuracy: 0.8542 - val_loss: 2.0461 - val_accuracy: 0.7812\n",
            "Epoch 77/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9245 - accuracy: 0.8472 - val_loss: 2.0228 - val_accuracy: 0.7812\n",
            "Epoch 78/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.8993 - accuracy: 0.8646 - val_loss: 1.9991 - val_accuracy: 0.7812\n",
            "Epoch 79/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8741 - accuracy: 0.8646 - val_loss: 1.9750 - val_accuracy: 0.7812\n",
            "Epoch 80/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8486 - accuracy: 0.8646 - val_loss: 1.9511 - val_accuracy: 0.7812\n",
            "Epoch 81/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8230 - accuracy: 0.8715 - val_loss: 1.9265 - val_accuracy: 0.7812\n",
            "Epoch 82/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7973 - accuracy: 0.9167 - val_loss: 1.9026 - val_accuracy: 0.8125\n",
            "Epoch 83/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7716 - accuracy: 0.9271 - val_loss: 1.8786 - val_accuracy: 0.8438\n",
            "Epoch 84/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7459 - accuracy: 0.9479 - val_loss: 1.8544 - val_accuracy: 0.8438\n",
            "Epoch 85/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7202 - accuracy: 0.9549 - val_loss: 1.8303 - val_accuracy: 0.8438\n",
            "Epoch 86/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6950 - accuracy: 0.9549 - val_loss: 1.8064 - val_accuracy: 0.8438\n",
            "Epoch 87/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6698 - accuracy: 0.9549 - val_loss: 1.7816 - val_accuracy: 0.8438\n",
            "Epoch 88/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6444 - accuracy: 0.9549 - val_loss: 1.7578 - val_accuracy: 0.8438\n",
            "Epoch 89/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6195 - accuracy: 0.9549 - val_loss: 1.7332 - val_accuracy: 0.8438\n",
            "Epoch 90/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5948 - accuracy: 0.9549 - val_loss: 1.7100 - val_accuracy: 0.8438\n",
            "Epoch 91/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.5696 - accuracy: 0.9549 - val_loss: 1.6850 - val_accuracy: 0.8438\n",
            "Epoch 92/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5444 - accuracy: 0.9549 - val_loss: 1.6612 - val_accuracy: 0.8438\n",
            "Epoch 93/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5190 - accuracy: 0.9549 - val_loss: 1.6358 - val_accuracy: 0.8438\n",
            "Epoch 94/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4935 - accuracy: 0.9549 - val_loss: 1.6111 - val_accuracy: 0.8438\n",
            "Epoch 95/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4677 - accuracy: 0.9549 - val_loss: 1.5861 - val_accuracy: 0.8438\n",
            "Epoch 96/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4418 - accuracy: 0.9549 - val_loss: 1.5605 - val_accuracy: 0.8438\n",
            "Epoch 97/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4162 - accuracy: 0.9549 - val_loss: 1.5359 - val_accuracy: 0.8438\n",
            "Epoch 98/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3905 - accuracy: 0.9618 - val_loss: 1.5106 - val_accuracy: 0.9062\n",
            "Epoch 99/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3649 - accuracy: 0.9826 - val_loss: 1.4849 - val_accuracy: 0.9062\n",
            "Epoch 100/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3398 - accuracy: 0.9826 - val_loss: 1.4618 - val_accuracy: 0.9062\n",
            "Epoch 101/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3152 - accuracy: 0.9826 - val_loss: 1.4376 - val_accuracy: 0.9062\n",
            "Epoch 102/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2905 - accuracy: 0.9826 - val_loss: 1.4130 - val_accuracy: 0.9062\n",
            "Epoch 103/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2655 - accuracy: 0.9826 - val_loss: 1.3883 - val_accuracy: 0.9062\n",
            "Epoch 104/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2409 - accuracy: 0.9826 - val_loss: 1.3645 - val_accuracy: 0.9062\n",
            "Epoch 105/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2165 - accuracy: 0.9826 - val_loss: 1.3393 - val_accuracy: 0.9062\n",
            "Epoch 106/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1920 - accuracy: 0.9826 - val_loss: 1.3149 - val_accuracy: 0.9062\n",
            "Epoch 107/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1674 - accuracy: 0.9826 - val_loss: 1.2905 - val_accuracy: 1.0000\n",
            "Epoch 108/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1431 - accuracy: 0.9965 - val_loss: 1.2666 - val_accuracy: 1.0000\n",
            "Epoch 109/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1191 - accuracy: 1.0000 - val_loss: 1.2421 - val_accuracy: 1.0000\n",
            "Epoch 110/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0952 - accuracy: 1.0000 - val_loss: 1.2178 - val_accuracy: 1.0000\n",
            "Epoch 111/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0711 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 1.0000\n",
            "Epoch 112/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0473 - accuracy: 1.0000 - val_loss: 1.1689 - val_accuracy: 1.0000\n",
            "Epoch 113/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0239 - accuracy: 1.0000 - val_loss: 1.1456 - val_accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0007 - accuracy: 1.0000 - val_loss: 1.1226 - val_accuracy: 1.0000\n",
            "Epoch 115/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9778 - accuracy: 1.0000 - val_loss: 1.0993 - val_accuracy: 1.0000\n",
            "Epoch 116/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9549 - accuracy: 1.0000 - val_loss: 1.0762 - val_accuracy: 1.0000\n",
            "Epoch 117/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9322 - accuracy: 1.0000 - val_loss: 1.0527 - val_accuracy: 1.0000\n",
            "Epoch 118/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9096 - accuracy: 1.0000 - val_loss: 1.0296 - val_accuracy: 1.0000\n",
            "Epoch 119/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8872 - accuracy: 1.0000 - val_loss: 1.0061 - val_accuracy: 1.0000\n",
            "Epoch 120/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8653 - accuracy: 1.0000 - val_loss: 0.9837 - val_accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8434 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8218 - accuracy: 1.0000 - val_loss: 0.9385 - val_accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8002 - accuracy: 1.0000 - val_loss: 0.9156 - val_accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7794 - accuracy: 1.0000 - val_loss: 0.8944 - val_accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 1.0000 - val_loss: 0.8725 - val_accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 1.0000 - val_loss: 0.8514 - val_accuracy: 1.0000\n",
            "Epoch 127/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7192 - accuracy: 1.0000 - val_loss: 0.8302 - val_accuracy: 1.0000\n",
            "Epoch 128/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 1.0000 - val_loss: 0.8096 - val_accuracy: 1.0000\n",
            "Epoch 129/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 1.0000 - val_loss: 0.7884 - val_accuracy: 1.0000\n",
            "Epoch 130/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 1.0000 - val_loss: 0.7669 - val_accuracy: 1.0000\n",
            "Epoch 131/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 1.0000 - val_loss: 0.7462 - val_accuracy: 1.0000\n",
            "Epoch 132/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 1.0000\n",
            "Epoch 133/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 1.0000\n",
            "Epoch 134/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 1.0000\n",
            "Epoch 135/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 1.0000\n",
            "Epoch 137/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 1.0000\n",
            "Epoch 138/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 1.0000 - val_loss: 0.6080 - val_accuracy: 1.0000\n",
            "Epoch 139/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 1.0000\n",
            "Epoch 140/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 1.0000 - val_loss: 0.5715 - val_accuracy: 1.0000\n",
            "Epoch 141/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 1.0000\n",
            "Epoch 142/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 1.0000 - val_loss: 0.5350 - val_accuracy: 1.0000\n",
            "Epoch 143/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 1.0000 - val_loss: 0.5173 - val_accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 1.0000\n",
            "Epoch 150/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 1.0000\n",
            "Epoch 153/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3033 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2916 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2697 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 1.0000\n",
            "Epoch 162/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 1.0000\n",
            "Epoch 163/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.2029 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.1496 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1303 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1189 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 1.0000\n",
            "Epoch 180/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 1.0000\n",
            "Epoch 183/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
            "Epoch 195/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
            "Epoch 196/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
            "Epoch 200/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.8203e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 9.1462e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.5149e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.9107e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.3493e-04 - accuracy: 1.0000 - val_loss: 9.8474e-04 - val_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 6.8222e-04 - accuracy: 1.0000 - val_loss: 9.1883e-04 - val_accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.3339e-04 - accuracy: 1.0000 - val_loss: 8.5084e-04 - val_accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.8843e-04 - accuracy: 1.0000 - val_loss: 7.9026e-04 - val_accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.4611e-04 - accuracy: 1.0000 - val_loss: 7.3747e-04 - val_accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.0615e-04 - accuracy: 1.0000 - val_loss: 6.8656e-04 - val_accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 4.6836e-04 - accuracy: 1.0000 - val_loss: 6.3257e-04 - val_accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 4.3421e-04 - accuracy: 1.0000 - val_loss: 5.8766e-04 - val_accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 4.0261e-04 - accuracy: 1.0000 - val_loss: 5.3921e-04 - val_accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.7255e-04 - accuracy: 1.0000 - val_loss: 5.0445e-04 - val_accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.4447e-04 - accuracy: 1.0000 - val_loss: 4.6606e-04 - val_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.1814e-04 - accuracy: 1.0000 - val_loss: 4.2924e-04 - val_accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.9447e-04 - accuracy: 1.0000 - val_loss: 3.9853e-04 - val_accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7230e-04 - accuracy: 1.0000 - val_loss: 3.7066e-04 - val_accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5136e-04 - accuracy: 1.0000 - val_loss: 3.4061e-04 - val_accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.3227e-04 - accuracy: 1.0000 - val_loss: 3.1348e-04 - val_accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1436e-04 - accuracy: 1.0000 - val_loss: 2.8768e-04 - val_accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9797e-04 - accuracy: 1.0000 - val_loss: 2.6796e-04 - val_accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8307e-04 - accuracy: 1.0000 - val_loss: 2.4808e-04 - val_accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6936e-04 - accuracy: 1.0000 - val_loss: 2.3117e-04 - val_accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5683e-04 - accuracy: 1.0000 - val_loss: 2.1619e-04 - val_accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4446e-04 - accuracy: 1.0000 - val_loss: 1.9835e-04 - val_accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3296e-04 - accuracy: 1.0000 - val_loss: 1.8390e-04 - val_accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.2284e-04 - accuracy: 1.0000 - val_loss: 1.6908e-04 - val_accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1320e-04 - accuracy: 1.0000 - val_loss: 1.5483e-04 - val_accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0427e-04 - accuracy: 1.0000 - val_loss: 1.4158e-04 - val_accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.5899e-05 - accuracy: 1.0000 - val_loss: 1.2981e-04 - val_accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.8006e-05 - accuracy: 1.0000 - val_loss: 1.1879e-04 - val_accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 8.0686e-05 - accuracy: 1.0000 - val_loss: 1.1027e-04 - val_accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 7.4005e-05 - accuracy: 1.0000 - val_loss: 1.0149e-04 - val_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.7882e-05 - accuracy: 1.0000 - val_loss: 9.2153e-05 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.2298e-05 - accuracy: 1.0000 - val_loss: 8.4373e-05 - val_accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.7257e-05 - accuracy: 1.0000 - val_loss: 7.7370e-05 - val_accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.2673e-05 - accuracy: 1.0000 - val_loss: 7.1508e-05 - val_accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 4.8352e-05 - accuracy: 1.0000 - val_loss: 6.5306e-05 - val_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.4516e-05 - accuracy: 1.0000 - val_loss: 6.1090e-05 - val_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.0978e-05 - accuracy: 1.0000 - val_loss: 5.6456e-05 - val_accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.7794e-05 - accuracy: 1.0000 - val_loss: 5.2095e-05 - val_accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.4708e-05 - accuracy: 1.0000 - val_loss: 4.7915e-05 - val_accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1801e-05 - accuracy: 1.0000 - val_loss: 4.3919e-05 - val_accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9134e-05 - accuracy: 1.0000 - val_loss: 4.0246e-05 - val_accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.6722e-05 - accuracy: 1.0000 - val_loss: 3.6744e-05 - val_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4532e-05 - accuracy: 1.0000 - val_loss: 3.3642e-05 - val_accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.2509e-05 - accuracy: 1.0000 - val_loss: 3.0889e-05 - val_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.0650e-05 - accuracy: 1.0000 - val_loss: 2.8188e-05 - val_accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8933e-05 - accuracy: 1.0000 - val_loss: 2.5838e-05 - val_accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7358e-05 - accuracy: 1.0000 - val_loss: 2.3677e-05 - val_accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.5947e-05 - accuracy: 1.0000 - val_loss: 2.1848e-05 - val_accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4615e-05 - accuracy: 1.0000 - val_loss: 2.0079e-05 - val_accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.3396e-05 - accuracy: 1.0000 - val_loss: 1.8298e-05 - val_accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2290e-05 - accuracy: 1.0000 - val_loss: 1.6961e-05 - val_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1324e-05 - accuracy: 1.0000 - val_loss: 1.5586e-05 - val_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0388e-05 - accuracy: 1.0000 - val_loss: 1.4264e-05 - val_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 9.5180e-06 - accuracy: 1.0000 - val_loss: 1.2979e-05 - val_accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.7308e-06 - accuracy: 1.0000 - val_loss: 1.1898e-05 - val_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.0466e-06 - accuracy: 1.0000 - val_loss: 1.1038e-05 - val_accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.3855e-06 - accuracy: 1.0000 - val_loss: 1.0278e-05 - val_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 6.7638e-06 - accuracy: 1.0000 - val_loss: 9.3131e-06 - val_accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.2005e-06 - accuracy: 1.0000 - val_loss: 8.4563e-06 - val_accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.6839e-06 - accuracy: 1.0000 - val_loss: 7.6703e-06 - val_accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.2659e-06 - accuracy: 1.0000 - val_loss: 7.0445e-06 - val_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 4.8383e-06 - accuracy: 1.0000 - val_loss: 6.4410e-06 - val_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 4.4484e-06 - accuracy: 1.0000 - val_loss: 5.9418e-06 - val_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.1032e-06 - accuracy: 1.0000 - val_loss: 5.4277e-06 - val_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.7667e-06 - accuracy: 1.0000 - val_loss: 5.0068e-06 - val_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.4699e-06 - accuracy: 1.0000 - val_loss: 4.5784e-06 - val_accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2191e-06 - accuracy: 1.0000 - val_loss: 4.2692e-06 - val_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.9690e-06 - accuracy: 1.0000 - val_loss: 4.0494e-06 - val_accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.7468e-06 - accuracy: 1.0000 - val_loss: 3.6768e-06 - val_accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5518e-06 - accuracy: 1.0000 - val_loss: 3.4310e-06 - val_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3569e-06 - accuracy: 1.0000 - val_loss: 3.1553e-06 - val_accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1818e-06 - accuracy: 1.0000 - val_loss: 2.9057e-06 - val_accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.0183e-06 - accuracy: 1.0000 - val_loss: 2.6897e-06 - val_accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.8780e-06 - accuracy: 1.0000 - val_loss: 2.4997e-06 - val_accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7720e-06 - accuracy: 1.0000 - val_loss: 2.3507e-06 - val_accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6578e-06 - accuracy: 1.0000 - val_loss: 2.1830e-06 - val_accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.5481e-06 - accuracy: 1.0000 - val_loss: 2.0564e-06 - val_accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4404e-06 - accuracy: 1.0000 - val_loss: 1.8924e-06 - val_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.3515e-06 - accuracy: 1.0000 - val_loss: 1.7770e-06 - val_accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2716e-06 - accuracy: 1.0000 - val_loss: 1.6578e-06 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1805e-06 - accuracy: 1.0000 - val_loss: 1.5236e-06 - val_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1039e-06 - accuracy: 1.0000 - val_loss: 1.4342e-06 - val_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0249e-06 - accuracy: 1.0000 - val_loss: 1.3411e-06 - val_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.6982e-07 - accuracy: 1.0000 - val_loss: 1.2778e-06 - val_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.1352e-07 - accuracy: 1.0000 - val_loss: 1.2107e-06 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.5433e-07 - accuracy: 1.0000 - val_loss: 1.1288e-06 - val_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.0963e-07 - accuracy: 1.0000 - val_loss: 1.0692e-06 - val_accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 7.6700e-07 - accuracy: 1.0000 - val_loss: 1.0096e-06 - val_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.3181e-07 - accuracy: 1.0000 - val_loss: 9.3877e-07 - val_accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.8049e-07 - accuracy: 1.0000 - val_loss: 9.0152e-07 - val_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 6.3413e-07 - accuracy: 1.0000 - val_loss: 8.1584e-07 - val_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 5.9067e-07 - accuracy: 1.0000 - val_loss: 7.7858e-07 - val_accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.6417e-07 - accuracy: 1.0000 - val_loss: 7.5251e-07 - val_accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.3147e-07 - accuracy: 1.0000 - val_loss: 6.9663e-07 - val_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 5.0540e-07 - accuracy: 1.0000 - val_loss: 6.7055e-07 - val_accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.8429e-07 - accuracy: 1.0000 - val_loss: 6.1467e-07 - val_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.6442e-07 - accuracy: 1.0000 - val_loss: 6.0722e-07 - val_accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.4165e-07 - accuracy: 1.0000 - val_loss: 5.6997e-07 - val_accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 4.2634e-07 - accuracy: 1.0000 - val_loss: 5.5134e-07 - val_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.9364e-07 - accuracy: 1.0000 - val_loss: 5.4017e-07 - val_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.8826e-07 - accuracy: 1.0000 - val_loss: 5.1409e-07 - val_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.7625e-07 - accuracy: 1.0000 - val_loss: 4.8801e-07 - val_accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.5059e-07 - accuracy: 1.0000 - val_loss: 4.4331e-07 - val_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2948e-07 - accuracy: 1.0000 - val_loss: 4.3958e-07 - val_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.1748e-07 - accuracy: 1.0000 - val_loss: 3.8743e-07 - val_accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9513e-07 - accuracy: 1.0000 - val_loss: 3.8743e-07 - val_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.9264e-07 - accuracy: 1.0000 - val_loss: 3.8743e-07 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.8643e-07 - accuracy: 1.0000 - val_loss: 3.7625e-07 - val_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.6367e-07 - accuracy: 1.0000 - val_loss: 3.7253e-07 - val_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.5746e-07 - accuracy: 1.0000 - val_loss: 3.5018e-07 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4835e-07 - accuracy: 1.0000 - val_loss: 3.3900e-07 - val_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4711e-07 - accuracy: 1.0000 - val_loss: 3.3155e-07 - val_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.4297e-07 - accuracy: 1.0000 - val_loss: 3.2037e-07 - val_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3097e-07 - accuracy: 1.0000 - val_loss: 3.1665e-07 - val_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.3014e-07 - accuracy: 1.0000 - val_loss: 2.9430e-07 - val_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 2.1648e-07 - accuracy: 1.0000 - val_loss: 2.9430e-07 - val_accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.1524e-07 - accuracy: 1.0000 - val_loss: 2.7940e-07 - val_accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.0448e-07 - accuracy: 1.0000 - val_loss: 2.7567e-07 - val_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 2.0075e-07 - accuracy: 1.0000 - val_loss: 2.6450e-07 - val_accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.9040e-07 - accuracy: 1.0000 - val_loss: 2.4214e-07 - val_accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8875e-07 - accuracy: 1.0000 - val_loss: 2.4214e-07 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.8213e-07 - accuracy: 1.0000 - val_loss: 2.3469e-07 - val_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7757e-07 - accuracy: 1.0000 - val_loss: 2.4587e-07 - val_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.7757e-07 - accuracy: 1.0000 - val_loss: 2.2724e-07 - val_accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.6308e-07 - accuracy: 1.0000 - val_loss: 2.0862e-07 - val_accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4322e-07 - accuracy: 1.0000 - val_loss: 2.0862e-07 - val_accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.4239e-07 - accuracy: 1.0000 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2873e-07 - accuracy: 1.0000 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.2335e-07 - accuracy: 1.0000 - val_loss: 1.4901e-07 - val_accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2749e-07 - accuracy: 1.0000 - val_loss: 1.5274e-07 - val_accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2418e-07 - accuracy: 1.0000 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2542e-07 - accuracy: 1.0000 - val_loss: 1.4901e-07 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.2832e-07 - accuracy: 1.0000 - val_loss: 1.4529e-07 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2459e-07 - accuracy: 1.0000 - val_loss: 1.4901e-07 - val_accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.2459e-07 - accuracy: 1.0000 - val_loss: 1.3784e-07 - val_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.1424e-07 - accuracy: 1.0000 - val_loss: 1.4156e-07 - val_accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.2045e-07 - accuracy: 1.0000 - val_loss: 1.3784e-07 - val_accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1383e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 9.8927e-08 - accuracy: 1.0000 - val_loss: 1.1548e-07 - val_accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 9.1063e-08 - accuracy: 1.0000 - val_loss: 1.0058e-07 - val_accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.5268e-08 - accuracy: 1.0000 - val_loss: 1.0058e-07 - val_accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 8.4440e-08 - accuracy: 1.0000 - val_loss: 7.8231e-08 - val_accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 7.9887e-08 - accuracy: 1.0000 - val_loss: 1.0803e-07 - val_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.9059e-08 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 8.2784e-08 - accuracy: 1.0000 - val_loss: 7.0781e-08 - val_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.7403e-08 - accuracy: 1.0000 - val_loss: 7.0781e-08 - val_accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 7.2022e-08 - accuracy: 1.0000 - val_loss: 8.5682e-08 - val_accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 7.4506e-08 - accuracy: 1.0000 - val_loss: 7.0781e-08 - val_accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.2022e-08 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.7469e-08 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 6.7883e-08 - accuracy: 1.0000 - val_loss: 1.0803e-07 - val_accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.9125e-08 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.8297e-08 - accuracy: 1.0000 - val_loss: 8.5682e-08 - val_accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 7.3264e-08 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.5813e-08 - accuracy: 1.0000 - val_loss: 9.6858e-08 - val_accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 7.0781e-08 - accuracy: 1.0000 - val_loss: 7.8231e-08 - val_accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.7055e-08 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 6.2916e-08 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "22/29 [=====================>........] - ETA: 0s - loss: 7.1526e-08 - accuracy: 1.0000Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 6.7469e-08 - accuracy: 1.0000 - val_loss: 6.7055e-08 - val_accuracy: 1.0000\n",
            "Epoch 00417: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd9e01c9a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnvfipwoOPgN"
      },
      "source": [
        "History = model_SS.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz5ojF3QOPgS",
        "outputId": "c48803bc-3a4a-4710-ee14-83d8eb6e5ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(History.history['accuracy'])\n",
        "plt.title('Accuracy VS Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAsmBbW-OPgX",
        "outputId": "f18a09b2-a4e0-4815-af35-67b1db589f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(History.history['loss'])\n",
        "plt.title('Loss VS Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-24OmuxbOPgc"
      },
      "source": [
        "## Testing the Shallow Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-sOoy9FOPgd",
        "outputId": "3f813f0c-b342-4ae3-a1cd-06f9c344008d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "Loss,Accuracy=model_SS.evaluate(X_test,Y_test,verbose=1)\n",
        "print('Accuracy: ',Accuracy)\n",
        "print('Loss: ',Loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 7.7486e-08 - accuracy: 1.0000\n",
            "Accuracy:  1.0\n",
            "Loss:  7.748602826040951e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmrSMVAFOPgh"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09oPY_gUOPgi"
      },
      "source": [
        "Name='Model 3.3 - SS 39'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmTxz7dTOPgo"
      },
      "source": [
        "Name=Name + ' - ' + str(datetime.datetime.now()) + '.h5'\n",
        "model_SS.save('/content/drive/My Drive/AI Breaks Cryptography/Models/'+Name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz3FZKlSOPgs"
      },
      "source": [
        "## Decoding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8EL5uVhOPgv",
        "outputId": "b31a5c6a-1f03-45a7-b8ff-4b0ca29703ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "Categories=[i for i in CHOICES]\n",
        "Label_Encoding=LabelEncoder().fit_transform(Categories).reshape(-1,1)\n",
        "One_Hot_Encoding=OneHotEncoder().fit_transform(Label_Encoding).toarray()\n",
        "Categories_Dictionary={Categories[i]:One_Hot_Encoding[i] for i in range(len(Categories))}\n",
        "Categories_Dictionary_Reverse={tuple(One_Hot_Encoding[i]):Categories[i] for i in range(len(Categories))}\n",
        "print(Categories_Dictionary)\n",
        "print(Categories_Dictionary_Reverse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'A': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'B': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'C': array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'D': array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'E': array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'F': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'G': array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'H': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'I': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'J': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'K': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'L': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'M': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'N': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'O': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'P': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'Q': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'R': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       1., 0., 0., 0., 0., 0., 0., 0., 0.]), 'S': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 1., 0., 0., 0., 0., 0., 0., 0.]), 'T': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'U': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 1., 0., 0., 0., 0., 0.]), 'V': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'W': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 1., 0., 0., 0.]), 'X': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 1., 0., 0.]), 'Y': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 1., 0.]), 'Z': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 1.])}\n",
            "{(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'A', (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'B', (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'C', (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'D', (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'E', (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'F', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'G', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'H', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'I', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'J', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'K', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'L', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'M', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'N', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'O', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'P', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'Q', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'R', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'S', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'T', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'U', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0): 'V', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0): 'W', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0): 'X', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0): 'Y', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0): 'Z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqKACZpmOPgz"
      },
      "source": [
        "def Decode(character,Categories_Dictionary_Reverse=Categories_Dictionary_Reverse):\n",
        "  #print(np.array(Categories_Dictionary[character]).shape)\n",
        "  prediction=model_SS.predict(np.array(Categories_Dictionary[character]).reshape(1,26))\n",
        "  prediction=prediction>=prediction.max()\n",
        "  #print(prediction)\n",
        "  temp=[0.0 for i in range(26)]\n",
        "  for i in range(len(prediction[0])):\n",
        "    if prediction[0][i]==True:\n",
        "      temp[i]=1\n",
        "  return Categories_Dictionary_Reverse[tuple(temp)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlEcAjMEOPg5",
        "outputId": "97fb0493-0335-4dfd-c728-e9eaff592aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "character='S'\n",
        "print(character)\n",
        "print(Decode(character))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S\n",
            "K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUIzASudOPg9"
      },
      "source": [
        "## AI Based Decryption of Simple Substitution Cipher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D75TYeYqOPg-",
        "outputId": "edb4a1de-3e48-4cba-bc46-5a9faef8bc09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "MESSAGE=\"ISAA PROJECT REVIEW\"\n",
        "MESSAGE=MESSAGE.upper()\n",
        "print(\"\\t\\tOriginal Message:\\t\\t\\t\\t\\t\\t\",MESSAGE)\n",
        "ENCRYPTED_MESSAGE=SimpleSubstitutionCipher_encryption(MESSAGE,KEY)\n",
        "print(\"\\n\\n\\t\\tMessage after Encryption using Simple Substitution Cipher:\\t\",ENCRYPTED_MESSAGE)\n",
        "#print(\"Key used for Encryption: \",KEY)\n",
        "DECRYPTED_MESSAGE=''\n",
        "for i in ENCRYPTED_MESSAGE:\n",
        "  if i==' ':\n",
        "    DECRYPTED_MESSAGE+=i\n",
        "  else:\n",
        "    DECRYPTED_MESSAGE+=Decode(i)\n",
        "print(\"\\n\\n\\t\\tMessage after AI based Decryption:\\t\\t\\t\\t\",DECRYPTED_MESSAGE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tOriginal Message:\t\t\t\t\t\t ISAA PROJECT REVIEW\n",
            "\n",
            "\n",
            "\t\tMessage after Encryption using Simple Substitution Cipher:\t ILPP GKFWEOM KEQIEU\n",
            "\n",
            "\n",
            "\t\tMessage after AI based Decryption:\t\t\t\t ISAA PROJECT REVIEW\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyLVzT2gD8sf"
      },
      "source": [
        "# Observation: The AI model has 100% accuracy of decrypting an encrypted password"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CltxYj2MNxsC"
      },
      "source": [
        "# Caesar Cipher (Protected Version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrcSgEUfNxsJ"
      },
      "source": [
        "**Note**: Variable Key is used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fSU-FTHNxsH"
      },
      "source": [
        "## Known-Plaintext Attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCBpVzKRNxsV"
      },
      "source": [
        "### Password Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzlbbHzSNxsW"
      },
      "source": [
        "PASSWORD_SIZE=8"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_KE3p8zNxsd"
      },
      "source": [
        "### Dataset Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d1yklFNNxsf"
      },
      "source": [
        "DATASET_SIZE=50"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8VbsGCVNxsm"
      },
      "source": [
        "### Generation of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf1jnrPKNxsn",
        "outputId": "58a48153-569e-4142-e556-703c6a43da7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "CHOICES=CaesarCipher_characterset()\n",
        "CHOICES"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThVlQJRDNxsx",
        "outputId": "19b77568-75d8-4633-f43b-193e8f7f226d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for i in range(DATASET_SIZE):\n",
        "  temp=''\n",
        "  for j in range(PASSWORD_SIZE):\n",
        "    temp+=random.choice(CHOICES)\n",
        "  x.append(temp)\n",
        "  age = random.randint(12,120)\n",
        "  KEY = age % 26;\n",
        "  y.append(CaesarCipher_encryption(temp,KEY))\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['RQJDPQEF', 'TLHDGUQL', 'YIOMVUBB', 'NBMECQJL', 'TOIILJAF', 'JBUCTJKI', 'MEIHYXMP', 'AVSCAWHB', 'WEHMEYDQ', 'YENTHTBR', 'ABJAQDIQ', 'IDPITQRK', 'IYMCHOIS', 'XCUZRNXX', 'RLVWRKRE', 'NFVDYBJX', 'IQRJIQZJ', 'AXDFUSKL', 'MFOTOMZB', 'ONAJEWZG', 'SSFMNFEZ', 'BJGTCWFQ', 'BENZRSXD', 'SUZJXXAT', 'HSKDGFOJ', 'IKVPPGZZ', 'XSBCSCTR', 'ZJOWBGFO', 'CXEDOAUJ', 'GKVJNBYX', 'NKPYGYAQ', 'BVCUZCDE', 'PBIPAUQQ', 'GVKKKBWD', 'NGKMYGSL', 'YVPRYIXP', 'WPFODQII', 'QUFUGDDH', 'MQBGQDIN', 'BCLNAJEV', 'DJEDJYXR', 'CIRVJJOP', 'EXQNQVBU', 'MJYZUJPE', 'IBCPVZHV', 'SROTZHNB', 'EIBJXHIE', 'XAUZVDOQ', 'JTQWWQIB', 'LKFTHMRT']\n",
            "['WVOIUVJK', 'SKGCFTPK', 'EOUSBAHH', 'CQBTRFYA', 'AVPPSQHM', 'EWPXOEFD', 'PHLKBAPS', 'KFCMKGRL', 'YGJOGAFS', 'YENTHTBR', 'TUCTJWBJ', 'WRDWHEFY', 'VLZPUBVF', 'HMEJBXHH', 'DXHIDWDQ', 'HZPXSVDR', 'QYZRQYHR', 'ZWCETRJK', 'XQZEZXKM', 'JIVEZRUB', 'YYLSTLKF', 'CKHUDXGR', 'CFOASTYE', 'PRWGUUXQ', 'XIATWVEZ', 'XZKEEVOO', 'VQZAQARP', 'GQVDINMV', 'GBIHSEYN', 'ZDOCGURQ', 'HEJSASUK', 'ICJBGJKL', 'JVCJUOKK', 'YNCCCTOV', 'RKOQCKWP', 'ROIKRBQI', 'WPFODQII', 'GKVKWTTX', 'ZDOTDQVA', 'KLUWJSNE', 'PVQPVKJD', 'EKTXLLQR', 'KDWTWBHA', 'PMBCXMSH', 'ZSTGMQYM', 'POLQWEKY', 'YCVDRBCY', 'RUOTPXIK', 'WGDJJDVO', 'XWRFTYDF']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4ggmXBkNxs7",
        "outputId": "29e930bd-d960-49a3-cb89-f3cd2748380f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "Data=pd.DataFrame({'Plaintext':x,'Ciphertext':y})\n",
        "Data.head(15)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plaintext</th>\n",
              "      <th>Ciphertext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RQJDPQEF</td>\n",
              "      <td>WVOIUVJK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TLHDGUQL</td>\n",
              "      <td>SKGCFTPK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>YIOMVUBB</td>\n",
              "      <td>EOUSBAHH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NBMECQJL</td>\n",
              "      <td>CQBTRFYA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TOIILJAF</td>\n",
              "      <td>AVPPSQHM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>JBUCTJKI</td>\n",
              "      <td>EWPXOEFD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MEIHYXMP</td>\n",
              "      <td>PHLKBAPS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AVSCAWHB</td>\n",
              "      <td>KFCMKGRL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>WEHMEYDQ</td>\n",
              "      <td>YGJOGAFS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>YENTHTBR</td>\n",
              "      <td>YENTHTBR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ABJAQDIQ</td>\n",
              "      <td>TUCTJWBJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>IDPITQRK</td>\n",
              "      <td>WRDWHEFY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>IYMCHOIS</td>\n",
              "      <td>VLZPUBVF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>XCUZRNXX</td>\n",
              "      <td>HMEJBXHH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RLVWRKRE</td>\n",
              "      <td>DXHIDWDQ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Plaintext Ciphertext\n",
              "0   RQJDPQEF   WVOIUVJK\n",
              "1   TLHDGUQL   SKGCFTPK\n",
              "2   YIOMVUBB   EOUSBAHH\n",
              "3   NBMECQJL   CQBTRFYA\n",
              "4   TOIILJAF   AVPPSQHM\n",
              "5   JBUCTJKI   EWPXOEFD\n",
              "6   MEIHYXMP   PHLKBAPS\n",
              "7   AVSCAWHB   KFCMKGRL\n",
              "8   WEHMEYDQ   YGJOGAFS\n",
              "9   YENTHTBR   YENTHTBR\n",
              "10  ABJAQDIQ   TUCTJWBJ\n",
              "11  IDPITQRK   WRDWHEFY\n",
              "12  IYMCHOIS   VLZPUBVF\n",
              "13  XCUZRNXX   HMEJBXHH\n",
              "14  RLVWRKRE   DXHIDWDQ"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WShkUv-wNxtD"
      },
      "source": [
        "### Since Caesar Cipher is a Stream Cipher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxckUu13NxtE",
        "outputId": "912d54f6-ce8b-483f-8dfe-86e8d7cff717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "plaintext=[]\n",
        "ciphertext=[]\n",
        "for password in x:\n",
        "  for character in password:\n",
        "    plaintext.append(character)\n",
        "for Encrypted_password in y:\n",
        "  for character in Encrypted_password:\n",
        "    ciphertext.append(character)\n",
        "Data=pd.DataFrame({'Plaintext':plaintext,'Ciphertext':ciphertext})\n",
        "Data.head(15)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plaintext</th>\n",
              "      <th>Ciphertext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>R</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>J</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P</td>\n",
              "      <td>U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>E</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>F</td>\n",
              "      <td>K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>T</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>L</td>\n",
              "      <td>K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>H</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>D</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>G</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>U</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Q</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Plaintext Ciphertext\n",
              "0          R          W\n",
              "1          Q          V\n",
              "2          J          O\n",
              "3          D          I\n",
              "4          P          U\n",
              "5          Q          V\n",
              "6          E          J\n",
              "7          F          K\n",
              "8          T          S\n",
              "9          L          K\n",
              "10         H          G\n",
              "11         D          C\n",
              "12         G          F\n",
              "13         U          T\n",
              "14         Q          P"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKfKX-VyQNFj",
        "outputId": "ccbc0a34-b576-4d53-ff15-fba34a1561dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Data[Data[\"Ciphertext\"] == 'A']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Plaintext</th>\n",
              "      <th>Ciphertext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>U</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>L</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>X</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Y</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>Z</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>K</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>N</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>U</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Plaintext Ciphertext\n",
              "21          U          A\n",
              "31          L          A\n",
              "32          T          A\n",
              "53          X          A\n",
              "69          Y          A\n",
              "179         Z          A\n",
              "194         K          A\n",
              "211         C          A\n",
              "213         C          A\n",
              "244         G          A\n",
              "311         N          A\n",
              "343         U          A"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvXVWN1ZNxtL"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WalLImZXNxtN"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSKr6pQjNxtO",
        "outputId": "8722ea9d-514b-4752-9857-18b7467141af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plaintext=LabelEncoder().fit_transform(plaintext).reshape(-1, 1)\n",
        "ciphertext=LabelEncoder().fit_transform(ciphertext).reshape(-1, 1)\n",
        "X=OneHotEncoder().fit_transform(plaintext).toarray()\n",
        "Y=OneHotEncoder().fit_transform(ciphertext).toarray()\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4tXClb0NxtV"
      },
      "source": [
        "### Splitting the Dataset - Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRvFFiAoNxtX",
        "outputId": "41a7f72f-b704-44b2-997c-640d0a4126a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(Y,X,test_size=0.2,random_state=0)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gZG99DQNxth"
      },
      "source": [
        "## Training the Shallow Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPhmyWHANxtj",
        "outputId": "2bd9ca08-2811-4529-dc4b-69fd6d5d2c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_CC_P= models.Sequential()\n",
        "model_CC_P.add(layers.Dense(26, activation='relu',input_shape=(26,)))\n",
        "model_CC_P.add(layers.Dense(39, activation='relu'))\n",
        "model_CC_P.add(layers.Dense(26, activation='softmax'))\n",
        "model_CC_P.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 26)                702       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 39)                1053      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 26)                1040      \n",
            "=================================================================\n",
            "Total params: 2,795\n",
            "Trainable params: 2,795\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUFrUuLDNxtq"
      },
      "source": [
        "EarlyStopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min',restore_best_weights=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQUeq_A7Nxtx"
      },
      "source": [
        "model_CC_P.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzBaxcWXNxt3",
        "outputId": "f3a2ef4b-6657-4de2-fed9-2ae182a5fc96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_CC_P.fit(x=X_train,y=Y_train,epochs=1000,batch_size=10,validation_split=0.1,callbacks=EarlyStopping)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 3.2657 - accuracy: 0.0382 - val_loss: 3.2910 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2638 - accuracy: 0.0417 - val_loss: 3.2906 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2623 - accuracy: 0.0417 - val_loss: 3.2902 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2609 - accuracy: 0.0486 - val_loss: 3.2898 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2594 - accuracy: 0.0486 - val_loss: 3.2896 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2580 - accuracy: 0.0451 - val_loss: 3.2894 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.2566 - accuracy: 0.0451 - val_loss: 3.2891 - val_accuracy: 0.0312\n",
            "Epoch 8/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2552 - accuracy: 0.0417 - val_loss: 3.2890 - val_accuracy: 0.0312\n",
            "Epoch 9/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2538 - accuracy: 0.0417 - val_loss: 3.2889 - val_accuracy: 0.0312\n",
            "Epoch 10/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2524 - accuracy: 0.0521 - val_loss: 3.2888 - val_accuracy: 0.0312\n",
            "Epoch 11/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2510 - accuracy: 0.0556 - val_loss: 3.2887 - val_accuracy: 0.0312\n",
            "Epoch 12/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2497 - accuracy: 0.0660 - val_loss: 3.2886 - val_accuracy: 0.0312\n",
            "Epoch 13/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2483 - accuracy: 0.0694 - val_loss: 3.2885 - val_accuracy: 0.0312\n",
            "Epoch 14/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2470 - accuracy: 0.0694 - val_loss: 3.2885 - val_accuracy: 0.0312\n",
            "Epoch 15/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2457 - accuracy: 0.0729 - val_loss: 3.2884 - val_accuracy: 0.0312\n",
            "Epoch 16/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2444 - accuracy: 0.0660 - val_loss: 3.2884 - val_accuracy: 0.0312\n",
            "Epoch 17/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2432 - accuracy: 0.0694 - val_loss: 3.2883 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2418 - accuracy: 0.0799 - val_loss: 3.2884 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2406 - accuracy: 0.0833 - val_loss: 3.2885 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2393 - accuracy: 0.0833 - val_loss: 3.2885 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2380 - accuracy: 0.0833 - val_loss: 3.2885 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2367 - accuracy: 0.0833 - val_loss: 3.2884 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2355 - accuracy: 0.0833 - val_loss: 3.2884 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2342 - accuracy: 0.0833 - val_loss: 3.2884 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2330 - accuracy: 0.0833 - val_loss: 3.2885 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 3.2317 - accuracy: 0.0903 - val_loss: 3.2885 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "18/29 [=================>............] - ETA: 0s - loss: 3.2362 - accuracy: 0.0944Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 3.2304 - accuracy: 0.0903 - val_loss: 3.2886 - val_accuracy: 0.0000e+00\n",
            "Epoch 00027: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f30b00cab38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaxN62W7Nxt_"
      },
      "source": [
        "History = model_CC_P.history"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRJBcGTQNxuM",
        "outputId": "f3a504b7-a064-4ed7-a220-bc9b9733c19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(History.history['accuracy'])\n",
        "plt.title('Accuracy VS Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFxtW0PENxuV",
        "outputId": "180df15e-0b8a-4206-bcbf-93af57c4189a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(History.history['loss'])\n",
        "plt.title('Loss VS Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azj1CeLHNxuc"
      },
      "source": [
        "## Testing the Shallow Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsnZCtuRNxue",
        "outputId": "dba4f201-692f-415a-9509-f5a5db67f6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Loss,Accuracy=model_CC_P.evaluate(X_test,Y_test,verbose=1)\n",
        "print('Accuracy: ',Accuracy)\n",
        "print('Loss: ',Loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 2ms/step - loss: 3.2852 - accuracy: 0.0375\n",
            "Accuracy:  0.03750000149011612\n",
            "Loss:  3.285165309906006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdWyDkCaNxui"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZoXc9VDNxuk"
      },
      "source": [
        "Name='Model 4.3 - VK CC 39'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTQ6co0JNxuo"
      },
      "source": [
        "Name=Name + ' - ' + str(datetime.datetime.now()) + '.h5'\n",
        "model_CC_P.save('/content/drive/My Drive/AI Breaks Cryptography/Models/'+Name)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTuei6saNxur"
      },
      "source": [
        "## Decoding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhOxwvm8Nxus",
        "outputId": "57ad470c-3232-403e-b207-0d302dae9a6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Categories=[i for i in CHOICES]\n",
        "Label_Encoding=LabelEncoder().fit_transform(Categories).reshape(-1,1)\n",
        "One_Hot_Encoding=OneHotEncoder().fit_transform(Label_Encoding).toarray()\n",
        "Categories_Dictionary={Categories[i]:One_Hot_Encoding[i] for i in range(len(Categories))}\n",
        "Categories_Dictionary_Reverse={tuple(One_Hot_Encoding[i]):Categories[i] for i in range(len(Categories))}\n",
        "print(Categories_Dictionary)\n",
        "print(Categories_Dictionary_Reverse)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'A': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'B': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'C': array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'D': array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'E': array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'F': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'G': array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'H': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'I': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'J': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'K': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'L': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'M': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'N': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'O': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'P': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'Q': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'R': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       1., 0., 0., 0., 0., 0., 0., 0., 0.]), 'S': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 1., 0., 0., 0., 0., 0., 0., 0.]), 'T': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'U': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 1., 0., 0., 0., 0., 0.]), 'V': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'W': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 1., 0., 0., 0.]), 'X': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 1., 0., 0.]), 'Y': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 1., 0.]), 'Z': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 1.])}\n",
            "{(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'A', (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'B', (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'C', (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'D', (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'E', (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'F', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'G', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'H', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'I', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'J', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'K', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'L', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'M', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'N', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'O', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'P', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'Q', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'R', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'S', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'T', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0): 'U', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0): 'V', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0): 'W', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0): 'X', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0): 'Y', (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0): 'Z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6rOYBNANxuv"
      },
      "source": [
        "def Decode(character,Categories_Dictionary_Reverse=Categories_Dictionary_Reverse):\n",
        "  #print(np.array(Categories_Dictionary[character]).shape)\n",
        "  prediction=model_CC_P.predict(np.array(Categories_Dictionary[character]).reshape(1,26))\n",
        "  prediction=prediction>=prediction.max()\n",
        "  #print(prediction)\n",
        "  temp=[0.0 for i in range(26)]\n",
        "  for i in range(len(prediction[0])):\n",
        "    if prediction[0][i]==True:\n",
        "      temp[i]=1\n",
        "  return Categories_Dictionary_Reverse[tuple(temp)]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHWSIbmgNxuz",
        "outputId": "8057cf9c-8ac2-4d63-ccfa-a95261d7c9b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "character='G'\n",
        "print(character)\n",
        "print(Decode(character))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "G\n",
            "B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KyEsKwnNxu2"
      },
      "source": [
        "## AI Attempting to Decrypt Variable Key Implementation of Caesar Cipher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTRLDiDONxu2",
        "outputId": "80df610b-e5eb-4262-9bb1-79851f758f81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "MESSAGE=\"CHRISTEEN T JOSE\"\n",
        "MESSAGE=MESSAGE.upper()\n",
        "print(\"\\t\\tOriginal Message:\\t\\t\\t\\t\",MESSAGE)\n",
        "ENCRYPTED_MESSAGE=CaesarCipher_encryption(MESSAGE,KEY)\n",
        "print(\"\\n\\n\\t\\tMessage after Encryption using Caesar Cipher:\\t\",ENCRYPTED_MESSAGE)\n",
        "#print(\"Key used for Encryption: \",KEY)\n",
        "DECRYPTED_MESSAGE=''\n",
        "for i in ENCRYPTED_MESSAGE:\n",
        "  if i==' ':\n",
        "    DECRYPTED_MESSAGE+=i\n",
        "  else:\n",
        "    DECRYPTED_MESSAGE+=Decode(i)\n",
        "print(\"\\n\\n\\t\\tMessage after AI based Decryption:\\t\\t\",DECRYPTED_MESSAGE)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tOriginal Message:\t\t\t\t CHRISTEEN T JOSE\n",
            "\n",
            "\n",
            "\t\tMessage after Encryption using Caesar Cipher:\t OTDUEFQQZ F VAEQ\n",
            "\n",
            "\n",
            "\t\tMessage after AI based Decryption:\t\t XBJXAWJJB W WBAJ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7zk6xWCSJxW"
      },
      "source": [
        "# Observation: The accuracy of the AI model has been brought down to 3 - 6%"
      ]
    }
  ]
}